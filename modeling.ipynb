{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to predict success using ML models\n",
    "\n",
    "This notebook consists on an attempt of using our extracted features from the movie scripts in order to predict whether a movie will be successful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import operator\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the dataset with all the features, raw and also aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed Title</th>\n",
       "      <th>Success</th>\n",
       "      <th>n_unique_words_char_1</th>\n",
       "      <th>n_unique_words_char_2</th>\n",
       "      <th>n_unique_words_char_3</th>\n",
       "      <th>n_unique_words_char_4</th>\n",
       "      <th>n_unique_words_char_5</th>\n",
       "      <th>FK_read_level_char_1</th>\n",
       "      <th>FK_read_level_char_2</th>\n",
       "      <th>FK_read_level_char_3</th>\n",
       "      <th>...</th>\n",
       "      <th>tot_hw_sents</th>\n",
       "      <th>feel_ratio</th>\n",
       "      <th>fill_ratio</th>\n",
       "      <th>hw_ratio</th>\n",
       "      <th>main_char_rel_diag_length</th>\n",
       "      <th>stdvs_unique_words_above_mean</th>\n",
       "      <th>FK_read_level_mean_char</th>\n",
       "      <th>stdvs_n_stop_words_above_mean</th>\n",
       "      <th>stdvs_n_curse_words_above_mean</th>\n",
       "      <th>stdvs_n_mentions_others_above_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avatar</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>1</td>\n",
       "      <td>670</td>\n",
       "      <td>565</td>\n",
       "      <td>252</td>\n",
       "      <td>425</td>\n",
       "      <td>276</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>269</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.272267</td>\n",
       "      <td>39.537232</td>\n",
       "      <td>-0.090538</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.063141</td>\n",
       "      <td>0.106202</td>\n",
       "      <td>-0.541956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Dark Knight Rises</th>\n",
       "      <td>Dark-Knight-Rises,-The</td>\n",
       "      <td>1</td>\n",
       "      <td>531</td>\n",
       "      <td>514</td>\n",
       "      <td>506</td>\n",
       "      <td>418</td>\n",
       "      <td>434</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>0.040289</td>\n",
       "      <td>0.089876</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>23.705825</td>\n",
       "      <td>0.255438</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.789323</td>\n",
       "      <td>-0.686754</td>\n",
       "      <td>-0.176310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Avengers</th>\n",
       "      <td>Avengers,-The</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>623</td>\n",
       "      <td>359</td>\n",
       "      <td>425</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.296175</td>\n",
       "      <td>0.242623</td>\n",
       "      <td>30.146047</td>\n",
       "      <td>-0.118151</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>-0.709410</td>\n",
       "      <td>-0.438622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pirates of the Caribbean: Dead Man's Chest</th>\n",
       "      <td>Pirates-of-the-Caribbean-Dead-Man's-Chest</td>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "      <td>373</td>\n",
       "      <td>285</td>\n",
       "      <td>378</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>0.168757</td>\n",
       "      <td>36.743621</td>\n",
       "      <td>-0.481995</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.057889</td>\n",
       "      <td>-0.732066</td>\n",
       "      <td>-0.867858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Men in Black 3</th>\n",
       "      <td>Men-in-Black-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1206</td>\n",
       "      <td>867</td>\n",
       "      <td>234</td>\n",
       "      <td>209</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>277</td>\n",
       "      <td>0.021722</td>\n",
       "      <td>0.127112</td>\n",
       "      <td>0.222848</td>\n",
       "      <td>57.328163</td>\n",
       "      <td>0.742729</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.533814</td>\n",
       "      <td>-0.437539</td>\n",
       "      <td>1.349863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      Processed Title  \\\n",
       "                                                                                        \n",
       "Avatar                                                                         Avatar   \n",
       "The Dark Knight Rises                                          Dark-Knight-Rises,-The   \n",
       "The Avengers                                                            Avengers,-The   \n",
       "Pirates of the Caribbean: Dead Man's Chest  Pirates-of-the-Caribbean-Dead-Man's-Chest   \n",
       "Men in Black 3                                                         Men-in-Black-3   \n",
       "\n",
       "                                            Success  n_unique_words_char_1  \\\n",
       "                                                                             \n",
       "Avatar                                            1                    670   \n",
       "The Dark Knight Rises                             1                    531   \n",
       "The Avengers                                      1                    560   \n",
       "Pirates of the Caribbean: Dead Man's Chest        1                    629   \n",
       "Men in Black 3                                    1                   1206   \n",
       "\n",
       "                                            n_unique_words_char_2  \\\n",
       "                                                                    \n",
       "Avatar                                                        565   \n",
       "The Dark Knight Rises                                         514   \n",
       "The Avengers                                                  623   \n",
       "Pirates of the Caribbean: Dead Man's Chest                    373   \n",
       "Men in Black 3                                                867   \n",
       "\n",
       "                                            n_unique_words_char_3  \\\n",
       "                                                                    \n",
       "Avatar                                                        252   \n",
       "The Dark Knight Rises                                         506   \n",
       "The Avengers                                                  359   \n",
       "Pirates of the Caribbean: Dead Man's Chest                    285   \n",
       "Men in Black 3                                                234   \n",
       "\n",
       "                                            n_unique_words_char_4  \\\n",
       "                                                                    \n",
       "Avatar                                                        425   \n",
       "The Dark Knight Rises                                         418   \n",
       "The Avengers                                                  425   \n",
       "Pirates of the Caribbean: Dead Man's Chest                    378   \n",
       "Men in Black 3                                                209   \n",
       "\n",
       "                                            n_unique_words_char_5  \\\n",
       "                                                                    \n",
       "Avatar                                                        276   \n",
       "The Dark Knight Rises                                         434   \n",
       "The Avengers                                                  205   \n",
       "Pirates of the Caribbean: Dead Man's Chest                    281   \n",
       "Men in Black 3                                                185   \n",
       "\n",
       "                                            FK_read_level_char_1  \\\n",
       "                                                                   \n",
       "Avatar                                                         2   \n",
       "The Dark Knight Rises                                          2   \n",
       "The Avengers                                                   2   \n",
       "Pirates of the Caribbean: Dead Man's Chest                     2   \n",
       "Men in Black 3                                                 2   \n",
       "\n",
       "                                            FK_read_level_char_2  \\\n",
       "                                                                   \n",
       "Avatar                                                         2   \n",
       "The Dark Knight Rises                                          2   \n",
       "The Avengers                                                   3   \n",
       "Pirates of the Caribbean: Dead Man's Chest                     1   \n",
       "Men in Black 3                                                 3   \n",
       "\n",
       "                                            FK_read_level_char_3  ...  \\\n",
       "                                                                  ...   \n",
       "Avatar                                                         2  ...   \n",
       "The Dark Knight Rises                                          3  ...   \n",
       "The Avengers                                                   3  ...   \n",
       "Pirates of the Caribbean: Dead Man's Chest                     1  ...   \n",
       "Men in Black 3                                                 2  ...   \n",
       "\n",
       "                                            tot_hw_sents  feel_ratio  \\\n",
       "                                                                       \n",
       "Avatar                                               269    0.016194   \n",
       "The Dark Knight Rises                                208    0.040289   \n",
       "The Avengers                                         222    0.036066   \n",
       "Pirates of the Caribbean: Dead Man's Chest           148    0.025086   \n",
       "Men in Black 3                                       277    0.021722   \n",
       "\n",
       "                                            fill_ratio  hw_ratio  \\\n",
       "                                                                   \n",
       "Avatar                                        0.008097  0.272267   \n",
       "The Dark Knight Rises                         0.089876  0.214876   \n",
       "The Avengers                                  0.296175  0.242623   \n",
       "Pirates of the Caribbean: Dead Man's Chest    0.064994  0.168757   \n",
       "Men in Black 3                                0.127112  0.222848   \n",
       "\n",
       "                                            main_char_rel_diag_length  \\\n",
       "                                                                        \n",
       "Avatar                                                      39.537232   \n",
       "The Dark Knight Rises                                       23.705825   \n",
       "The Avengers                                                30.146047   \n",
       "Pirates of the Caribbean: Dead Man's Chest                  36.743621   \n",
       "Men in Black 3                                              57.328163   \n",
       "\n",
       "                                            stdvs_unique_words_above_mean  \\\n",
       "                                                                            \n",
       "Avatar                                                          -0.090538   \n",
       "The Dark Knight Rises                                            0.255438   \n",
       "The Avengers                                                    -0.118151   \n",
       "Pirates of the Caribbean: Dead Man's Chest                      -0.481995   \n",
       "Men in Black 3                                                   0.742729   \n",
       "\n",
       "                                            FK_read_level_mean_char  \\\n",
       "                                                                      \n",
       "Avatar                                                          2.4   \n",
       "The Dark Knight Rises                                           2.2   \n",
       "The Avengers                                                    3.0   \n",
       "Pirates of the Caribbean: Dead Man's Chest                      1.8   \n",
       "Men in Black 3                                                  2.8   \n",
       "\n",
       "                                            stdvs_n_stop_words_above_mean  \\\n",
       "                                                                            \n",
       "Avatar                                                           0.063141   \n",
       "The Dark Knight Rises                                            0.789323   \n",
       "The Avengers                                                    -0.004098   \n",
       "Pirates of the Caribbean: Dead Man's Chest                      -0.057889   \n",
       "Men in Black 3                                                   0.533814   \n",
       "\n",
       "                                            stdvs_n_curse_words_above_mean  \\\n",
       "                                                                             \n",
       "Avatar                                                            0.106202   \n",
       "The Dark Knight Rises                                            -0.686754   \n",
       "The Avengers                                                     -0.709410   \n",
       "Pirates of the Caribbean: Dead Man's Chest                       -0.732066   \n",
       "Men in Black 3                                                   -0.437539   \n",
       "\n",
       "                                            stdvs_n_mentions_others_above_mean  \n",
       "                                                                                \n",
       "Avatar                                                               -0.541956  \n",
       "The Dark Knight Rises                                                -0.176310  \n",
       "The Avengers                                                         -0.438622  \n",
       "Pirates of the Caribbean: Dead Man's Chest                           -0.867858  \n",
       "Men in Black 3                                                        1.349863  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"feat_extraction/movies_with_feats_pedro.csv\"\n",
    "\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df.index.name = \"\"\n",
    "del df[\"Unnamed: 0.1\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'neg': 0.13, 'neu': 0.727, 'pos': 0.144, 'compound': 0.9994}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"polarity_of_mentions_char_1\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Processed Title\", \"Success\", \"polarity_of_mentions_char_1\", \"polarity_of_mentions_char_2\", \n",
    "             \"polarity_of_mentions_char_3\", \"polarity_of_mentions_char_4\", \"polarity_of_mentions_char_5\"], axis=1)\n",
    "y = df[\"Success\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the [point-biserial correlation coefficient](https://en.wikipedia.org/wiki/Point-biserial_correlation_coefficient) between our target and each of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 most negative correlated features:\n",
      "\n",
      "n_unique_words_char_5 : -0.0625966891567367\n",
      "hw_per_sent_char_4 : -0.05588129871815716\n",
      "num_pass_sents_char_2 : -0.05359501936621161\n",
      "feels_per_sent_char_4 : -0.05223540032604609\n",
      "passive_ratio : -0.051792981697795296\n",
      "\n",
      "Top 5 most positive correlated features:\n",
      "\n",
      "overall_polarity_char_2 : 0.07773382447981679\n",
      "compound_polarity_of_mentions_char_2 : 0.06305073767233481\n",
      "pos_polarity_of_mentions_char_1 : 0.0592639484639471\n",
      "compound_polarity_of_mentions_char_5 : 0.05378153632926945\n",
      "overall_polarity_char_5 : 0.05155577879978894\n"
     ]
    }
   ],
   "source": [
    "corr = {}\n",
    "for feature in X.columns:\n",
    "    corr[feature] = pointbiserialr(X[feature].values, y.values)\n",
    "        \n",
    "sorted_corr = sorted(corr.items(), key=operator.itemgetter(1))\n",
    "print(\"\\nTop 5 most negative correlated features:\\n\")\n",
    "for i in sorted_corr[:5]:\n",
    "    print(i[0], \":\", i[1].correlation)\n",
    "print(\"\\nTop 5 most positive correlated features:\\n\")\n",
    "for i in sorted_corr[::-1][:5]:\n",
    "    print(i[0], \":\", i[1].correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this is not good news... Let's keep only the features with an absolute correlation greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_unique_words_char_5',\n",
       " 'hw_per_sent_char_4',\n",
       " 'num_pass_sents_char_2',\n",
       " 'feels_per_sent_char_4',\n",
       " 'passive_ratio',\n",
       " 'overall_polarity_char_5',\n",
       " 'compound_polarity_of_mentions_char_5',\n",
       " 'pos_polarity_of_mentions_char_1',\n",
       " 'compound_polarity_of_mentions_char_2',\n",
       " 'overall_polarity_char_2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres = 0.05\n",
    "feat_to_keep = [feat[0] for feat in sorted_corr if abs(feat[1].correlation) > thres]\n",
    "feat_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    540\n",
       "0    113\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[feat_to_keep]\n",
    "y = df[\"Success\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the class labels are not very balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify = y)\n",
    "st = StandardScaler()\n",
    "X_train_std = st.fit_transform(X_train)\n",
    "X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    162\n",
       " 0     34\n",
       " Name: Success, dtype: int64, 'No-info rate:', 0.826530612244898)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(), \"No-info rate:\", 162/(162+34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826530612244898"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train_std, y_train)\n",
    "logreg.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    1\n",
       "True          \n",
       "0           34\n",
       "1          162"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, logreg.predict(X_test_std), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this is not good. Our model is not learning, but predicting everything as successful. As the correlation was pointing, it seems that our features do not contain enough predictive power... Let's try to grid-search this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(metric=\"accuracy\"):\n",
    "\n",
    "    # The code below was taken from GWU MLI Class\n",
    "    clfs = {'lr': LogisticRegression(random_state=0),\n",
    "            'mlp': MLPClassifier(random_state=0),\n",
    "            'dt': DecisionTreeClassifier(random_state=0),\n",
    "            'rf': RandomForestClassifier(random_state=0),\n",
    "            'knn': KNeighborsClassifier(),\n",
    "            'gnb': GaussianNB(),\n",
    "            \"ada\": AdaBoostClassifier(random_state=0),\n",
    "           }\n",
    "    pipe_clfs = {}\n",
    "    for name, clf in clfs.items():\n",
    "        pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()), ('clf', clf)])\n",
    "    param_grids = {}\n",
    "    C_range = [10 ** i for i in range(-4, 5)]\n",
    "    param_grid = [{'clf__multi_class': ['ovr'], \n",
    "                   'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                   'clf__C': C_range},\n",
    "\n",
    "                  {'clf__multi_class': ['multinomial'],\n",
    "                   'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                   'clf__C': C_range}]\n",
    "    param_grids['lr'] = param_grid\n",
    "    param_grid = [{'clf__hidden_layer_sizes': [10, 100, 200],\n",
    "                   'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "    param_grids['mlp'] = param_grid\n",
    "    param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "                   'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "    param_grids['dt'] = param_grid\n",
    "    param_grid = [{'clf__n_estimators': [2, 10, 30],\n",
    "                   'clf__min_samples_split': [2, 10, 30],\n",
    "                   'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "    param_grids['rf'] = param_grid\n",
    "    param_grid = [{'clf__n_neighbors': list(range(1, 11))}]\n",
    "    param_grids['knn'] = param_grid\n",
    "    param_grid = [{'clf__var_smoothing': [10 ** i for i in range(-10, -7)]}]\n",
    "    param_grids['gnb'] = param_grid\n",
    "    param_grid = [{'clf__base_estimator': [DecisionTreeClassifier(max_depth=1), LogisticRegression(random_state=0), \n",
    "                                          ], \"clf__n_estimators\": [i*10 for i in range(2, 7)], \n",
    "                  \"clf__learning_rate\": [0.01, 0.1, 1], \"clf__algorithm\": [\"SAMME\", \"SAMME.R\"]}]\n",
    "    param_grids['ada'] = param_grid\n",
    "    best_score_param_estimators = []\n",
    "    for name in pipe_clfs.keys():\n",
    "        gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                          param_grid=param_grids[name],\n",
    "                          scoring=metric,\n",
    "                          n_jobs=-1,\n",
    "                          cv=StratifiedKFold(n_splits=10,\n",
    "                                             shuffle=True,\n",
    "                                             random_state=0))\n",
    "        start = time()\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        print(\"the gird-search took\", round(time() - start), \"seconds for\", name)\n",
    "        best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])\n",
    "    best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "    for best_score_param_estimator in best_score_param_estimators:\n",
    "        print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')\n",
    "        \n",
    "    return best_score_param_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gird-search took 8 seconds for lr\n",
      "the gird-search took 11 seconds for mlp\n",
      "the gird-search took 0 seconds for dt\n",
      "the gird-search took 3 seconds for rf\n",
      "the gird-search took 1 seconds for knn\n",
      "the gird-search took 0 seconds for gnb\n",
      "the gird-search took 17 seconds for ada\n",
      "[0.8293216630196937, {'clf__C': 0.001, 'clf__multi_class': 'ovr', 'clf__solver': 'liblinear'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.8293216630196937, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 30, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.8293216630196937, {'clf__algorithm': 'SAMME', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'clf__learning_rate': 0.01, 'clf__n_estimators': 20}, <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>]\n",
      "\n",
      "[0.8271334792122538, {'clf__activation': 'identity', 'clf__hidden_layer_sizes': 10}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.8271334792122538, {'clf__min_samples_leaf': 30, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.8140043763676149, {'clf__n_neighbors': 9}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.774617067833698, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = find_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].fit(X_train_std, y_train)\n",
    "best_score_param_estimators[0][2].score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1\n",
       "True             \n",
       "0          0   34\n",
       "1          1  161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][2].predict(X_test_std), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we tune to maximize accuracy, we still don't learn anything. Let's go for the least amount of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gird-search took 5 seconds for lr\n",
      "the gird-search took 12 seconds for mlp\n",
      "the gird-search took 0 seconds for dt\n",
      "the gird-search took 3 seconds for rf\n",
      "the gird-search took 1 seconds for knn\n",
      "the gird-search took 0 seconds for gnb\n",
      "the gird-search took 20 seconds for ada\n",
      "[0.8462899024804271, {'clf__min_samples_leaf': 10, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.8461221873195848, {'clf__n_neighbors': 2}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.8355593470591097, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 10, 'clf__n_estimators': 2}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.8312369021238799, {'clf__algorithm': 'SAMME', 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'clf__learning_rate': 1, 'clf__n_estimators': 40}, <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>]\n",
      "\n",
      "[0.8304400680768295, {'clf__C': 0.001, 'clf__multi_class': 'ovr', 'clf__solver': 'liblinear'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.8294753393063415, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n",
      "[0.8289740458739492, {'clf__activation': 'relu', 'clf__hidden_layer_sizes': 200}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = find_best_model(metric=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551020408163265"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].fit(X_train_std, y_train)\n",
    "best_score_param_estimators[0][2].score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1\n",
       "True              \n",
       "0           2   32\n",
       "1          16  146"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][2].predict(X_test_std), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse than before. We only get two less false positives but 16 false negatives..! \n",
    "\n",
    "Let's try with oversampling and undersampling, although this will probably not work. it seems that our features are pretty much irrelevant in regards to success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([113, 113]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "np.unique(y_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(X_resampled, y_resampled,\n",
    "                                                    test_size=0.3, random_state=0, stratify = y_resampled)\n",
    "X_train_std = st.fit_transform(X_train)\n",
    "X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204081632653061"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train_std, y_train)\n",
    "logreg.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gird-search took 3 seconds for lr\n",
      "the gird-search took 6 seconds for mlp\n",
      "the gird-search took 0 seconds for dt\n",
      "the gird-search took 2 seconds for rf\n",
      "the gird-search took 0 seconds for knn\n",
      "the gird-search took 0 seconds for gnb\n",
      "the gird-search took 13 seconds for ada\n",
      "[0.6012658227848101, {'clf__activation': 'logistic', 'clf__hidden_layer_sizes': 100}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.5886075949367089, {'clf__C': 0.1, 'clf__multi_class': 'multinomial', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.5822784810126582, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'clf__learning_rate': 0.1, 'clf__n_estimators': 50}, <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>]\n",
      "\n",
      "[0.569620253164557, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 30, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.569620253164557, {'clf__n_neighbors': 4}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.5379746835443038, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n",
      "[0.5189873417721519, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = find_best_model(metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5357142857142857"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].fit(X_train_std, y_train)\n",
    "best_score_param_estimators[0][2].score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([540, 540]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rus = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "np.unique(y_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(X_resampled, y_resampled,\n",
    "                                                    test_size=0.3, random_state=0, stratify = y_resampled)\n",
    "X_train_std = st.fit_transform(X_train)\n",
    "X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576530612244898"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train_std, y_train)\n",
    "logreg.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gird-search took 4 seconds for lr\n",
      "the gird-search took 20 seconds for mlp\n",
      "the gird-search took 0 seconds for dt\n",
      "the gird-search took 3 seconds for rf\n",
      "the gird-search took 2 seconds for knn\n",
      "the gird-search took 0 seconds for gnb\n",
      "the gird-search took 26 seconds for ada\n",
      "[0.921957671957672, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.8822751322751323, {'clf__n_neighbors': 1}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.8637566137566137, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.7328042328042328, {'clf__activation': 'relu', 'clf__hidden_layer_sizes': 200}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.6904761904761905, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'clf__learning_rate': 1, 'clf__n_estimators': 60}, <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>]\n",
      "\n",
      "[0.5317460317460317, {'clf__C': 0.0001, 'clf__multi_class': 'ovr', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.5105820105820106, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = find_best_model(metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061224489795918"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].fit(X_train_std, y_train)\n",
    "best_score_param_estimators[0][2].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse... Let us do the same using all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Processed Title\", \"Success\", \"polarity_of_mentions_char_1\", \"polarity_of_mentions_char_2\", \n",
    "             \"polarity_of_mentions_char_3\", \"polarity_of_mentions_char_4\", \"polarity_of_mentions_char_5\"], axis=1)\n",
    "y = df[\"Success\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify = y)\n",
    "st = StandardScaler()\n",
    "X_train_std = st.fit_transform(X_train)\n",
    "X_test_std = st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    162\n",
       " 0     34\n",
       " Name: Success, dtype: int64, 'No-info rate:', 0.826530612244898)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(), \"No-info rate:\", 162/(162+34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8163265306122449"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train_std, y_train)\n",
    "logreg.score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1\n",
       "True             \n",
       "0          2   32\n",
       "1          4  158"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, logreg.predict(X_test_std), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gird-search took 15 seconds for lr\n",
      "the gird-search took 29 seconds for mlp\n",
      "the gird-search took 1 seconds for dt\n",
      "the gird-search took 4 seconds for rf\n",
      "the gird-search took 2 seconds for knn\n",
      "the gird-search took 0 seconds for gnb\n",
      "the gird-search took 34 seconds for ada\n",
      "[0.8471063396104105, {'clf__n_neighbors': 2}, <class 'sklearn.neighbors.classification.KNeighborsClassifier'>]\n",
      "\n",
      "[0.8352044807914365, {'clf__activation': 'tanh', 'clf__hidden_layer_sizes': 10}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.8348245967095926, {'clf__algorithm': 'SAMME.R', 'clf__base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'clf__learning_rate': 1, 'clf__n_estimators': 50}, <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>]\n",
      "\n",
      "[0.8337007268856157, {'clf__min_samples_leaf': 10, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.831792809413729, {'clf__C': 0.001, 'clf__multi_class': 'ovr', 'clf__solver': 'liblinear'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.8315341599805495, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.8227975485880255, {'clf__var_smoothing': 1e-10}, <class 'sklearn.naive_bayes.GaussianNB'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = find_best_model(metric=\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5510204081632653"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].fit(X_train_std, y_train)\n",
    "best_score_param_estimators[0][2].score(X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][2].predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1\n",
       "True              \n",
       "0           7   27\n",
       "1          61  101"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][2].predict(X_test_std), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still nothing useful. We can try changing the success threshold in order to make it more balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"success_data.csv\"\n",
    "df1 = pd.read_csv(path, index_col=0)\n",
    "\n",
    "def discretize(row):\n",
    "    if row[\"Worldwide ROI (%)\"] > 75:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"Success\"] = df1.apply(discretize, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    454\n",
       "0    199\n",
       "Name: Success, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"Processed Title\", \"Success\", \"polarity_of_mentions_char_1\", \"polarity_of_mentions_char_2\", \n",
    "             \"polarity_of_mentions_char_3\", \"polarity_of_mentions_char_4\", \"polarity_of_mentions_char_5\"], axis=1)\n",
    "y = df[\"Success\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6412213740458015"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nop. We also tried with different thresholds for ROI, and also with domestic ROI, but there is just no pattern to be learnt. We removed movies with very large ROI and tried some other combinations of features, but still, no luck. We can conclude that linguistic features such as the ones we extracted about the characters dialogues are great for clustering such characters, but do not hold any real relation with a movie's success. Instead, much more complex features regarding the relationship's between characters, the story progression and quality, will probably be the ones for which an underlying function between them and some portion of a movie's success actually exists."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
