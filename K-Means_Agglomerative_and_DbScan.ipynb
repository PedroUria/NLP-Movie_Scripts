{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusts = range(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tot_feel</th>\n",
       "      <th>tot_fill</th>\n",
       "      <th>tot_hw</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>polarity</th>\n",
       "      <th>uniqwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KAT____10-Things-I-Hate-About-You_script</th>\n",
       "      <td>leave it i said , leave it ! why did n't we ju...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-0.9984</td>\n",
       "      <td>603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATRICK____10-Things-I-Hate-About-You_script</th>\n",
       "      <td>i missed you . it was a bratwurst . i was eati...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>-0.9952</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIANCA____10-Things-I-Hate-About-You_script</th>\n",
       "      <td>did you change your hair ? you might wan na th...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAMERON____10-Things-I-Hate-About-You_script</th>\n",
       "      <td>i do n't think so , ma'am so they tell me ... ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MICHAEL____10-Things-I-Hate-About-You_script</th>\n",
       "      <td>you the new guy ? c'mon . i 'm supposed to giv...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              0  \\\n",
       "Unnamed: 0                                                                                        \n",
       "KAT____10-Things-I-Hate-About-You_script      leave it i said , leave it ! why did n't we ju...   \n",
       "PATRICK____10-Things-I-Hate-About-You_script  i missed you . it was a bratwurst . i was eati...   \n",
       "BIANCA____10-Things-I-Hate-About-You_script   did you change your hair ? you might wan na th...   \n",
       "CAMERON____10-Things-I-Hate-About-You_script  i do n't think so , ma'am so they tell me ... ...   \n",
       "MICHAEL____10-Things-I-Hate-About-You_script  you the new guy ? c'mon . i 'm supposed to giv...   \n",
       "\n",
       "                                              tot_feel  tot_fill  tot_hw  \\\n",
       "Unnamed: 0                                                                 \n",
       "KAT____10-Things-I-Hate-About-You_script          18.0       0.0    87.0   \n",
       "PATRICK____10-Things-I-Hate-About-You_script       6.0      13.0    60.0   \n",
       "BIANCA____10-Things-I-Hate-About-You_script       13.0       9.0    75.0   \n",
       "CAMERON____10-Things-I-Hate-About-You_script       8.0       8.0    58.0   \n",
       "MICHAEL____10-Things-I-Hate-About-You_script       7.0       3.0    46.0   \n",
       "\n",
       "                                              stopwords  polarity  uniqwords  \n",
       "Unnamed: 0                                                                    \n",
       "KAT____10-Things-I-Hate-About-You_script           97.0   -0.9984      603.0  \n",
       "PATRICK____10-Things-I-Hate-About-You_script       86.0   -0.9952      465.0  \n",
       "BIANCA____10-Things-I-Hate-About-You_script        85.0    0.9968      418.0  \n",
       "CAMERON____10-Things-I-Hate-About-You_script       71.0    0.9951      316.0  \n",
       "MICHAEL____10-Things-I-Hate-About-You_script       83.0    0.9984      419.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(os.getcwd() + '/top5_chars.csv')\n",
    "X.index = X.iloc[:,0]\n",
    "X.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "X.drop(['cursewords','FK','0'],axis=1,inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, we will actually have to break these guys down into senteces... \n",
    "# so I will have to do the sentence tokenizer :) \n",
    "def jacardian_distance(document_1_data, document_2_data):\n",
    "\n",
    "    \n",
    "    #for key in processed_article_hash.keys(): \n",
    "    #art_uniq_ws[key] = []\n",
    "    #for sent in processed_article_hash[key]:\n",
    "    #    art_uniq_ws[key].extend(sent)\n",
    "    #    art_uniq_ws[key] = list(set(art_uniq_ws[key]))\n",
    "    d1_uniqs = []\n",
    "    for sent in document_1_data:\n",
    "        d1_uniqs.extend(sent)\n",
    "        d1_uniqs = list(set(d1_uniqs))\n",
    "    d2_uniqs = []\n",
    "    for sent in document_2_data:\n",
    "        d2_uniqs.extend(sent)\n",
    "        d2_uniqs = list(set(d2_uniqs))\n",
    "        \n",
    "    words_in_doc_1_not_in_doc_2 = [value for value in d1_uniqs if value not in d2_uniqs]\n",
    "    words_in_doc_2_not_in_doc_1 = [value for value in d2_uniqs if value not in d1_uniqs]\n",
    "    words_in_both_doc_1_and_doc_2 = [value for value in d1_uniqs if value in d2_uniqs]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #overlap = [value for value in d1_uniqs if value in d2_uniqs] \n",
    "    #in1Not2 = [value for value in d1_uniqs if value not in d2_uniqs]\n",
    "    #in2Not1 = [value for value in d2_uniqs if value not in d1_uniqs]\n",
    "   # print(len(in1Not2))\n",
    "    #print(len(in2Not1))\n",
    "    #print(len(sv))\n",
    "   # print(len(sv)+len(in2Not1)+len(in1Not2))\n",
    "\n",
    "   # sv = d2_uniqs + d1_uniqs\n",
    "   # sv = list(set(sv))\n",
    "   # print(len(overlap))\n",
    "    \n",
    "    \n",
    "    \n",
    "    jacardian = len(words_in_both_doc_1_and_doc_2)/(len(words_in_both_doc_1_and_doc_2) + len(words_in_doc_1_not_in_doc_2) + len(words_in_doc_2_not_in_doc_1)) # divide the counts appropiately\n",
    "    \n",
    "    return jacardian\n",
    "    \n",
    "    \n",
    "    \n",
    "#Cosine Similarity: Here we want to create vector representations for each document. Specifically, we want to come up with a vector that is based on the list of all words that occur across both documents. Then for each document we will create a vector that includes the counts of the number of time a word occurs in the document.\n",
    "\n",
    "#So if the document 1 is: \"the ship sails at midnight\" and document 2 is: \"the crow flies at noon.\" We would be creating a vector like: [the, ship, sails, at, midnight, crow, flies, noon]. Then we would calculate the values of the vector for each document. For document 1: [1,1,1,1,1,0,0,0] and for document 2: [1,0,0,1,0,1,1,1]. With these two vectors we would simply take the dot product and that would provide the cosine similarity. \n",
    "\n",
    "def cosine_similarity(document_1_data, document_2_data):\n",
    "    document_vector_word_index = [] # here fill this with an ordered list of all the unique words across both documents\n",
    "    d1_uniqs = []\n",
    "    d1_nun = []\n",
    "    for sent in document_1_data:\n",
    "        d1_uniqs.extend(sent)\n",
    "        d1_nun.extend(sent)\n",
    "        d1_uniqs = list(set(d1_uniqs))\n",
    "    d2_uniqs = []\n",
    "    d2_nun = []\n",
    "    for sent in document_2_data:\n",
    "        d2_uniqs.extend(sent)\n",
    "        d2_uniqs = list(set(d2_uniqs))\n",
    "        d2_nun.extend(sent)\n",
    "\n",
    "    \n",
    "    all_words = d1_nun+d2_nun   \n",
    "\n",
    "    overlap = d1_uniqs + d2_uniqs \n",
    "    # so this is all of the unique words across the two documents\n",
    "    document_vector_word_index += list(set(overlap))\n",
    "    \n",
    "\n",
    "    document_1_vector = list(np.zeros(len(document_vector_word_index)))  # fill in the array with the frequency of the words in the document\n",
    "    document_2_vector = list(np.zeros(len(document_vector_word_index))) # fill in the array with the frequency of the words in the document\n",
    "\n",
    "    for wOrd in d1_nun:\n",
    "        document_1_vector[document_vector_word_index.index(wOrd)] +=1\n",
    "    \n",
    "    for wOrd in d2_nun:\n",
    "        document_2_vector[document_vector_word_index.index(wOrd)] +=1\n",
    "    \n",
    "    d1_norm = (np.sum(np.array(document_1_vector)**2))**(1/2)\n",
    "    d2_norm = (np.sum(np.array(document_2_vector)**2))**(1/2)\n",
    "    \n",
    "    cosSim = np.dot(document_1_vector,document_2_vector)/(d1_norm*d2_norm)\n",
    "\n",
    "\n",
    "    \n",
    "    return (cosSim)\n",
    "#document_1_vector,document_2_vector,document_vector_word_index, are the things I tried to return in testing\n",
    "#dot_product_of_two_document_vectors # you can refer to the numpy information on how to calculate the dot product of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to store your table data... you could use a hash or some other data structure. \n",
    "# We just want it to identify which document is being compared to which other document.\n",
    "\n",
    "data_structure_for_jacard_similarity = []\n",
    "data_structure_for_cosine_similarity = []\n",
    "# so I think what I'm ACTUALLY going to do here \n",
    "# is just append a new column\n",
    "# and then say the column is .... \n",
    "# so we are comparing each character to every OTHER character (including themselves)\n",
    "for char_1_index in char_series.index:\n",
    "    for char_2_index in char_series.index:\n",
    "        # we have the nested for loops as one way to compare each document to each other document\n",
    "        data_structure_for_jacard_similarity.append(jacardian_distance(char_series[char_1_index], char_series[char_2_index]))\n",
    "        data_structure_for_cosine_similarity.append(cosine_similarity(char_series[char_1_index], char_series[char_2_index]))\n",
    "\n",
    "# finally, find some way to present this data back. Either as a straight table or a heatmap.\n",
    "# so... yeah.... I can probably keep the rows the same as what they were... TECHNICALLY.... \n",
    "colz = char_series.index\n",
    "rowz = char_series.index\n",
    "\n",
    "\n",
    "for movChar in char_series_index:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-de40192e3dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'char_series' is not defined"
     ]
    }
   ],
   "source": [
    "pd.Series(np.nan,index = char_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
