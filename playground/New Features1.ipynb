{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(653, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('latest_dataset.csv')\n",
    "df = df.drop('Success',axis=1)\n",
    "\n",
    "success_data = pd.read_csv(\"../success_data.csv\").drop('Unnamed: 0', axis=1) #, index_col=0)\n",
    "print(success_data.shape)\n",
    "upper = success_data['Domestic ROI (%)'].mean() + (3 * success_data['Domestic ROI (%)'].std())\n",
    "lower = success_data['Domestic ROI (%)'].mean() - (3 * success_data['Domestic ROI (%)'].std())\n",
    "success_data = success_data[(success_data['Domestic ROI (%)']>=lower) & (success_data['Domestic ROI (%)']<= upper)]\n",
    "success_data['Success'] = (success_data['Domestic ROI (%)']>70)*1\n",
    "\n",
    "\n",
    "filterCols = ['passive_ratio', 'pct_coref_sents', 'tot_unique_per_sent','tot_stop_per_sent', 'std_of_overall_polarity', \n",
    "              'wav_polarity', 'avg_FK', 'sign_check_char_mention_polairty', 'std_of_char_mention_polarity', \n",
    "              'Processed Title', 'avg_sim_score', 'Success']\n",
    "\n",
    "df = pd.merge(df, success_data, on='Processed Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('latest_dataset.csv')\n",
    "df = df[filterCols]\n",
    "df = df.replace('?',np.NaN)\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "X = df.drop('Success',axis=1)\n",
    "y = df['Success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passive_ratio</th>\n",
       "      <th>pct_coref_sents</th>\n",
       "      <th>tot_unique_per_sent</th>\n",
       "      <th>tot_stop_per_sent</th>\n",
       "      <th>std_of_overall_polarity</th>\n",
       "      <th>wav_polarity</th>\n",
       "      <th>avg_FK</th>\n",
       "      <th>sign_check_char_mention_polairty</th>\n",
       "      <th>std_of_char_mention_polarity</th>\n",
       "      <th>Processed Title</th>\n",
       "      <th>avg_sim_score</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031377</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>2.214575</td>\n",
       "      <td>0.548583</td>\n",
       "      <td>0.778124</td>\n",
       "      <td>0.812752</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.780684</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>0.297514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030601</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>2.373770</td>\n",
       "      <td>0.585792</td>\n",
       "      <td>0.775803</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.787237</td>\n",
       "      <td>Avengers,-The</td>\n",
       "      <td>0.284754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029767</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>2.172969</td>\n",
       "      <td>0.464200</td>\n",
       "      <td>0.784953</td>\n",
       "      <td>0.903355</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796159</td>\n",
       "      <td>Men-in-Black-3</td>\n",
       "      <td>0.264265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027927</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>2.360902</td>\n",
       "      <td>0.625134</td>\n",
       "      <td>0.871314</td>\n",
       "      <td>-0.294680</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906034</td>\n",
       "      <td>Guardians-of-the-Galaxy-Vol-2</td>\n",
       "      <td>0.256726</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>2.792185</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.701191</td>\n",
       "      <td>0.687086</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.174552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.033865</td>\n",
       "      <td>3.027888</td>\n",
       "      <td>0.896414</td>\n",
       "      <td>0.947472</td>\n",
       "      <td>-0.384526</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>Terminator-Salvation</td>\n",
       "      <td>0.242028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>2.453145</td>\n",
       "      <td>0.681643</td>\n",
       "      <td>0.955209</td>\n",
       "      <td>-0.374191</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486071</td>\n",
       "      <td>Mummy,-The</td>\n",
       "      <td>0.243462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.165217</td>\n",
       "      <td>2.323478</td>\n",
       "      <td>0.546087</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>Great-Gatsby,-The</td>\n",
       "      <td>0.226589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.760989</td>\n",
       "      <td>0.500916</td>\n",
       "      <td>0.789093</td>\n",
       "      <td>0.815739</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746365</td>\n",
       "      <td>Thor-Ragnarok</td>\n",
       "      <td>0.193483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>1.650267</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.997581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398839</td>\n",
       "      <td>Up</td>\n",
       "      <td>0.259401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.042122</td>\n",
       "      <td>0.101404</td>\n",
       "      <td>2.308892</td>\n",
       "      <td>0.517161</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>-0.303792</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972449</td>\n",
       "      <td>Snow-White-and-the-Huntsman</td>\n",
       "      <td>0.304867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.055598</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>1.827799</td>\n",
       "      <td>0.451737</td>\n",
       "      <td>0.779195</td>\n",
       "      <td>0.799250</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796003</td>\n",
       "      <td>Interstellar</td>\n",
       "      <td>0.267558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.033923</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>2.762537</td>\n",
       "      <td>0.827434</td>\n",
       "      <td>0.787090</td>\n",
       "      <td>0.709021</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.788938</td>\n",
       "      <td>Beauty-and-the-Beast</td>\n",
       "      <td>0.216011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.030713</td>\n",
       "      <td>0.101966</td>\n",
       "      <td>2.261671</td>\n",
       "      <td>0.615479</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.996019</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>Shrek-the-Third</td>\n",
       "      <td>0.329644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.076205</td>\n",
       "      <td>1.940902</td>\n",
       "      <td>0.494557</td>\n",
       "      <td>0.898668</td>\n",
       "      <td>0.472405</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942295</td>\n",
       "      <td>Inception</td>\n",
       "      <td>0.357022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.031826</td>\n",
       "      <td>2.673367</td>\n",
       "      <td>0.807370</td>\n",
       "      <td>0.955550</td>\n",
       "      <td>0.647977</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769453</td>\n",
       "      <td>Godzilla</td>\n",
       "      <td>0.219338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.053076</td>\n",
       "      <td>0.054282</td>\n",
       "      <td>2.755127</td>\n",
       "      <td>0.693607</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.998016</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>Curious-Case-of-Benjamin-Button,-The</td>\n",
       "      <td>0.252845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>2.106814</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>0.761241</td>\n",
       "      <td>-0.841044</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>War-for-the-Planet-of-the-Apes</td>\n",
       "      <td>0.254866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.026002</td>\n",
       "      <td>0.055255</td>\n",
       "      <td>1.785482</td>\n",
       "      <td>0.472373</td>\n",
       "      <td>0.833011</td>\n",
       "      <td>-0.900051</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488463</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>0.345820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028837</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>1.992558</td>\n",
       "      <td>0.477209</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.839308</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791876</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>0.203930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.073684</td>\n",
       "      <td>2.726316</td>\n",
       "      <td>1.021053</td>\n",
       "      <td>0.770002</td>\n",
       "      <td>-0.679607</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791353</td>\n",
       "      <td>Matrix-Reloaded,-The</td>\n",
       "      <td>0.196067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.152145</td>\n",
       "      <td>1.897453</td>\n",
       "      <td>0.402815</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>-0.122701</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979469</td>\n",
       "      <td>Hancock</td>\n",
       "      <td>0.285196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.039688</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>2.290826</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.797893</td>\n",
       "      <td>-0.544129</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>Thor</td>\n",
       "      <td>0.392277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.155923</td>\n",
       "      <td>2.786585</td>\n",
       "      <td>0.486934</td>\n",
       "      <td>0.782786</td>\n",
       "      <td>-0.479574</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797329</td>\n",
       "      <td>X-Men-Origins-Wolverine</td>\n",
       "      <td>0.286076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.061831</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>2.853746</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.709987</td>\n",
       "      <td>-0.731764</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819356</td>\n",
       "      <td>Angels-&amp;-Demons</td>\n",
       "      <td>0.270651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.044957</td>\n",
       "      <td>2.099635</td>\n",
       "      <td>0.636695</td>\n",
       "      <td>0.763929</td>\n",
       "      <td>0.706697</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793411</td>\n",
       "      <td>How-to-Train-Your-Dragon-2</td>\n",
       "      <td>0.344482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.056944</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>3.151389</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.972260</td>\n",
       "      <td>0.053391</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976931</td>\n",
       "      <td>Star-Trek</td>\n",
       "      <td>0.152254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.071267</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>2.852941</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.790838</td>\n",
       "      <td>0.102751</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798478</td>\n",
       "      <td>Last-Samurai,-The</td>\n",
       "      <td>0.234878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.103155</td>\n",
       "      <td>2.158981</td>\n",
       "      <td>0.608010</td>\n",
       "      <td>0.749102</td>\n",
       "      <td>0.824663</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>Spider-Man</td>\n",
       "      <td>0.230468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.157083</td>\n",
       "      <td>2.417952</td>\n",
       "      <td>0.485975</td>\n",
       "      <td>0.934925</td>\n",
       "      <td>-0.210251</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973199</td>\n",
       "      <td>Watchmen</td>\n",
       "      <td>0.255021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.016289</td>\n",
       "      <td>0.089943</td>\n",
       "      <td>1.160057</td>\n",
       "      <td>0.357649</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.998408</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>Visitor,-The</td>\n",
       "      <td>0.233579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.118717</td>\n",
       "      <td>2.151872</td>\n",
       "      <td>0.556150</td>\n",
       "      <td>0.794862</td>\n",
       "      <td>0.382194</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798811</td>\n",
       "      <td>Cooler,-The</td>\n",
       "      <td>0.276665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.086316</td>\n",
       "      <td>2.256842</td>\n",
       "      <td>0.573684</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.035818</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797901</td>\n",
       "      <td>Four-Rooms</td>\n",
       "      <td>0.215945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.023622</td>\n",
       "      <td>0.053301</td>\n",
       "      <td>1.507571</td>\n",
       "      <td>0.346457</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>0.992982</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397056</td>\n",
       "      <td>Gods-and-Monsters</td>\n",
       "      <td>0.230918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.054374</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>2.511820</td>\n",
       "      <td>0.693853</td>\n",
       "      <td>0.050210</td>\n",
       "      <td>0.957139</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465085</td>\n",
       "      <td>Margin-Call</td>\n",
       "      <td>0.338230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.041946</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>2.567114</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.779222</td>\n",
       "      <td>0.219430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.396040</td>\n",
       "      <td>Feast</td>\n",
       "      <td>0.173672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.050064</td>\n",
       "      <td>0.046213</td>\n",
       "      <td>2.906290</td>\n",
       "      <td>0.688062</td>\n",
       "      <td>0.773527</td>\n",
       "      <td>0.707026</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774675</td>\n",
       "      <td>Trainspotting</td>\n",
       "      <td>0.226502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>3.209393</td>\n",
       "      <td>0.798434</td>\n",
       "      <td>0.911151</td>\n",
       "      <td>-0.459179</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921583</td>\n",
       "      <td>French-Connection,-The</td>\n",
       "      <td>0.173180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>2.540138</td>\n",
       "      <td>0.595183</td>\n",
       "      <td>0.786940</td>\n",
       "      <td>0.633745</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797495</td>\n",
       "      <td>American-Splendor</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.044167</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>1.315833</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.771047</td>\n",
       "      <td>0.822340</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380096</td>\n",
       "      <td>Buried</td>\n",
       "      <td>0.244021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.044048</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>2.682143</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.661264</td>\n",
       "      <td>0.392683</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707446</td>\n",
       "      <td>Beasts-of-the-Southern-Wild</td>\n",
       "      <td>0.397301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.038952</td>\n",
       "      <td>0.165212</td>\n",
       "      <td>2.273338</td>\n",
       "      <td>0.434520</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>-0.997674</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>I-Spit-on-Your-Grave</td>\n",
       "      <td>0.541255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.023520</td>\n",
       "      <td>0.151663</td>\n",
       "      <td>2.258719</td>\n",
       "      <td>0.502839</td>\n",
       "      <td>0.891562</td>\n",
       "      <td>-0.178484</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917956</td>\n",
       "      <td>In-the-Bedroom</td>\n",
       "      <td>0.369024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.039032</td>\n",
       "      <td>0.062451</td>\n",
       "      <td>2.170180</td>\n",
       "      <td>0.472287</td>\n",
       "      <td>0.792091</td>\n",
       "      <td>0.805896</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.791539</td>\n",
       "      <td>From-Here-to-Eternity</td>\n",
       "      <td>0.156483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.048343</td>\n",
       "      <td>2.069061</td>\n",
       "      <td>0.600829</td>\n",
       "      <td>0.887332</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760278</td>\n",
       "      <td>Repo-Man</td>\n",
       "      <td>0.263240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.159844</td>\n",
       "      <td>2.588694</td>\n",
       "      <td>0.820663</td>\n",
       "      <td>0.692544</td>\n",
       "      <td>-0.528594</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762718</td>\n",
       "      <td>Blood-Simple</td>\n",
       "      <td>0.212417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.037488</td>\n",
       "      <td>1.499531</td>\n",
       "      <td>0.449859</td>\n",
       "      <td>0.937368</td>\n",
       "      <td>-0.114162</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794507</td>\n",
       "      <td>Killing-Zoe</td>\n",
       "      <td>0.219068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>2.338252</td>\n",
       "      <td>0.562997</td>\n",
       "      <td>0.650274</td>\n",
       "      <td>-0.734014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706499</td>\n",
       "      <td>Believer,-The</td>\n",
       "      <td>0.197499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.032911</td>\n",
       "      <td>0.087342</td>\n",
       "      <td>2.507595</td>\n",
       "      <td>0.615190</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>Hebrew-Hammer,-The</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.049102</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>2.736527</td>\n",
       "      <td>0.674251</td>\n",
       "      <td>0.782361</td>\n",
       "      <td>0.377101</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796196</td>\n",
       "      <td>Dear-White-People</td>\n",
       "      <td>0.271042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>3.022727</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.074116</td>\n",
       "      <td>-0.962198</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>Reservoir-Dogs</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.021075</td>\n",
       "      <td>0.047418</td>\n",
       "      <td>1.978925</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.257433</td>\n",
       "      <td>0.956677</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>Taxi-Driver</td>\n",
       "      <td>0.219098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>1.704545</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.798280</td>\n",
       "      <td>-0.121325</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880659</td>\n",
       "      <td>Hellraiser</td>\n",
       "      <td>0.242416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.032226</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>2.140987</td>\n",
       "      <td>0.536757</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.991656</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>Sessions,-The</td>\n",
       "      <td>0.275139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.069155</td>\n",
       "      <td>1.671789</td>\n",
       "      <td>0.537870</td>\n",
       "      <td>0.113859</td>\n",
       "      <td>0.955425</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>Martha-Marcy-May-Marlene</td>\n",
       "      <td>0.357128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>1.707879</td>\n",
       "      <td>0.511515</td>\n",
       "      <td>0.751138</td>\n",
       "      <td>-0.912995</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750490</td>\n",
       "      <td>Frozen-River</td>\n",
       "      <td>0.253777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.025830</td>\n",
       "      <td>0.061808</td>\n",
       "      <td>1.879151</td>\n",
       "      <td>0.473247</td>\n",
       "      <td>0.859388</td>\n",
       "      <td>-0.102563</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817862</td>\n",
       "      <td>Battle-of-Shaker-Heights,-The</td>\n",
       "      <td>0.231712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.028190</td>\n",
       "      <td>0.025223</td>\n",
       "      <td>2.020772</td>\n",
       "      <td>0.632047</td>\n",
       "      <td>0.936554</td>\n",
       "      <td>-0.469530</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726326</td>\n",
       "      <td>Fruitvale-Station</td>\n",
       "      <td>0.214703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.040102</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>1.850683</td>\n",
       "      <td>0.459898</td>\n",
       "      <td>0.789634</td>\n",
       "      <td>0.844464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797186</td>\n",
       "      <td>Brick</td>\n",
       "      <td>0.374844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>1.764664</td>\n",
       "      <td>0.255007</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.999264</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>It-Happened-One-Night</td>\n",
       "      <td>0.334266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passive_ratio  pct_coref_sents  tot_unique_per_sent  tot_stop_per_sent  \\\n",
       "0         0.031377         0.054656             2.214575           0.548583   \n",
       "1         0.030601         0.065574             2.373770           0.585792   \n",
       "2         0.029767         0.185841             2.172969           0.464200   \n",
       "3         0.027927         0.060150             2.360902           0.625134   \n",
       "4         0.035524         0.046181             2.792185           0.857904   \n",
       "5         0.063745         0.033865             3.027888           0.896414   \n",
       "6         0.047497         0.021823             2.453145           0.681643   \n",
       "7         0.033913         0.165217             2.323478           0.546087   \n",
       "8         0.030220         0.035714             1.760989           0.500916   \n",
       "9         0.023529         0.047059             1.650267           0.502674   \n",
       "10        0.042122         0.101404             2.308892           0.517161   \n",
       "11        0.055598         0.043243             1.827799           0.451737   \n",
       "12        0.033923         0.075221             2.762537           0.827434   \n",
       "13        0.030713         0.101966             2.261671           0.615479   \n",
       "14        0.038880         0.076205             1.940902           0.494557   \n",
       "15        0.033501         0.031826             2.673367           0.807370   \n",
       "16        0.053076         0.054282             2.755127           0.693607   \n",
       "17        0.022099         0.016575             2.106814           0.745856   \n",
       "18        0.026002         0.055255             1.785482           0.472373   \n",
       "19        0.028837         0.037209             1.992558           0.477209   \n",
       "20        0.021053         0.073684             2.726316           1.021053   \n",
       "21        0.023458         0.152145             1.897453           0.402815   \n",
       "22        0.039688         0.137931             2.290826           0.439167   \n",
       "23        0.030488         0.155923             2.786585           0.486934   \n",
       "24        0.061831         0.026159             2.853746           0.655172   \n",
       "25        0.027947         0.044957             2.099635           0.636695   \n",
       "26        0.056944         0.050000             3.151389           0.736111   \n",
       "27        0.071267         0.067873             2.852941           0.712670   \n",
       "28        0.030340         0.103155             2.158981           0.608010   \n",
       "29        0.034362         0.157083             2.417952           0.485975   \n",
       "..             ...              ...                  ...                ...   \n",
       "497       0.016289         0.089943             1.160057           0.357649   \n",
       "498       0.036364         0.118717             2.151872           0.556150   \n",
       "499       0.022105         0.086316             2.256842           0.573684   \n",
       "500       0.023622         0.053301             1.507571           0.346457   \n",
       "501       0.054374         0.017730             2.511820           0.693853   \n",
       "502       0.041946         0.018456             2.567114           0.679530   \n",
       "503       0.050064         0.046213             2.906290           0.688062   \n",
       "504       0.046967         0.035225             3.209393           0.798434   \n",
       "505       0.048165         0.102064             2.540138           0.595183   \n",
       "506       0.044167         0.029167             1.315833           0.370000   \n",
       "507       0.044048         0.158333             2.682143           0.523810   \n",
       "508       0.038952         0.165212             2.273338           0.434520   \n",
       "509       0.023520         0.151663             2.258719           0.502839   \n",
       "510       0.039032         0.062451             2.170180           0.472287   \n",
       "511       0.013812         0.048343             2.069061           0.600829   \n",
       "512       0.035088         0.159844             2.588694           0.820663   \n",
       "513       0.021556         0.037488             1.499531           0.449859   \n",
       "514       0.045403         0.032917             2.338252           0.562997   \n",
       "515       0.032911         0.087342             2.507595           0.615190   \n",
       "516       0.049102         0.041916             2.736527           0.674251   \n",
       "517       0.066667         0.034848             3.022727           0.775758   \n",
       "518       0.021075         0.047418             1.978925           0.501581   \n",
       "519       0.022727         0.078125             1.704545           0.613636   \n",
       "520       0.032226         0.040282             2.140987           0.536757   \n",
       "521       0.026345         0.069155             1.671789           0.537870   \n",
       "522       0.030303         0.013333             1.707879           0.511515   \n",
       "523       0.025830         0.061808             1.879151           0.473247   \n",
       "524       0.028190         0.025223             2.020772           0.632047   \n",
       "525       0.040102         0.063140             1.850683           0.459898   \n",
       "526       0.046853         0.112303             1.764664           0.255007   \n",
       "\n",
       "     std_of_overall_polarity  wav_polarity  avg_FK  \\\n",
       "0                   0.778124      0.812752     2.4   \n",
       "1                   0.775803      0.683503     3.0   \n",
       "2                   0.784953      0.903355     2.8   \n",
       "3                   0.871314     -0.294680     2.4   \n",
       "4                   0.701191      0.687086     2.4   \n",
       "5                   0.947472     -0.384526     3.2   \n",
       "6                   0.955209     -0.374191     2.6   \n",
       "7                   0.004939      0.998431     2.8   \n",
       "8                   0.789093      0.815739     1.8   \n",
       "9                   0.004335      0.997581     1.0   \n",
       "10                  0.908462     -0.303792     2.2   \n",
       "11                  0.779195      0.799250     2.4   \n",
       "12                  0.787090      0.709021     2.2   \n",
       "13                  0.005286      0.996019     1.8   \n",
       "14                  0.898668      0.472405     2.6   \n",
       "15                  0.955550      0.647977     2.8   \n",
       "16                  0.002494      0.998016     3.4   \n",
       "17                  0.761241     -0.841044     0.8   \n",
       "18                  0.833011     -0.900051     0.8   \n",
       "19                  0.773700      0.839308     2.4   \n",
       "20                  0.770002     -0.679607     1.2   \n",
       "21                  0.977167     -0.122701     1.8   \n",
       "22                  0.797893     -0.544129     3.2   \n",
       "23                  0.782786     -0.479574     3.4   \n",
       "24                  0.709987     -0.731764     4.4   \n",
       "25                  0.763929      0.706697     1.4   \n",
       "26                  0.972260      0.053391     4.6   \n",
       "27                  0.790838      0.102751     4.2   \n",
       "28                  0.749102      0.824663     2.4   \n",
       "29                  0.934925     -0.210251     3.2   \n",
       "..                       ...           ...     ...   \n",
       "497                 0.013664      0.998408     0.8   \n",
       "498                 0.794862      0.382194     2.2   \n",
       "499                 0.797189      0.035818     2.8   \n",
       "500                 0.045498      0.992982     1.6   \n",
       "501                 0.050210      0.957139     2.6   \n",
       "502                 0.779222      0.219430     2.0   \n",
       "503                 0.773527      0.707026     2.6   \n",
       "504                 0.911151     -0.459179     2.8   \n",
       "505                 0.786940      0.633745     3.6   \n",
       "506                 0.771047      0.822340     2.4   \n",
       "507                 0.661264      0.392683     3.6   \n",
       "508                 0.001260     -0.997674     2.8   \n",
       "509                 0.891562     -0.178484     1.8   \n",
       "510                 0.792091      0.805896     2.4   \n",
       "511                 0.887332     -0.009569     1.4   \n",
       "512                 0.692544     -0.528594     1.8   \n",
       "513                 0.937368     -0.114162     1.4   \n",
       "514                 0.650274     -0.734014     3.0   \n",
       "515                 0.045441      0.989373     2.8   \n",
       "516                 0.782361      0.377101     2.6   \n",
       "517                 0.074116     -0.962198     3.2   \n",
       "518                 0.257433      0.956677     1.6   \n",
       "519                 0.798280     -0.121325     1.2   \n",
       "520                 0.033749      0.991656     3.0   \n",
       "521                 0.113859      0.955425     1.2   \n",
       "522                 0.751138     -0.912995     1.8   \n",
       "523                 0.859388     -0.102563     1.4   \n",
       "524                 0.936554     -0.469530     0.8   \n",
       "525                 0.789634      0.844464     1.0   \n",
       "526                 0.003015      0.999264     2.8   \n",
       "\n",
       "     sign_check_char_mention_polairty  std_of_char_mention_polarity  \\\n",
       "0                                   0                      0.780684   \n",
       "1                                   0                      0.787237   \n",
       "2                                   0                      0.796159   \n",
       "3                                   0                      0.906034   \n",
       "4                                   0                      0.705212   \n",
       "5                                   0                      0.741699   \n",
       "6                                   0                      0.486071   \n",
       "7                                   1                      0.000383   \n",
       "8                                   0                      0.746365   \n",
       "9                                   0                      0.398839   \n",
       "10                                  0                      0.972449   \n",
       "11                                  0                      0.796003   \n",
       "12                                  0                      0.788938   \n",
       "13                                  1                      0.005478   \n",
       "14                                  0                      0.942295   \n",
       "15                                  0                      0.769453   \n",
       "16                                  1                      0.001945   \n",
       "17                                  0                      0.762044   \n",
       "18                                  0                      0.488463   \n",
       "19                                  0                      0.791876   \n",
       "20                                  0                      0.791353   \n",
       "21                                  0                      0.979469   \n",
       "22                                  0                      0.799500   \n",
       "23                                  0                      0.797329   \n",
       "24                                  0                      0.819356   \n",
       "25                                  0                      0.793411   \n",
       "26                                  0                      0.976931   \n",
       "27                                  0                      0.798478   \n",
       "28                                  0                      0.780943   \n",
       "29                                  0                      0.973199   \n",
       "..                                ...                           ...   \n",
       "497                                 1                      0.003809   \n",
       "498                                 0                      0.798811   \n",
       "499                                 0                      0.797901   \n",
       "500                                 0                      0.397056   \n",
       "501                                 0                      0.465085   \n",
       "502                                 0                      0.396040   \n",
       "503                                 0                      0.774675   \n",
       "504                                 0                      0.921583   \n",
       "505                                 0                      0.797495   \n",
       "506                                 0                      0.380096   \n",
       "507                                 0                      0.707446   \n",
       "508                                -1                      0.000160   \n",
       "509                                 0                      0.917956   \n",
       "510                                 0                      0.791539   \n",
       "511                                 0                      0.760278   \n",
       "512                                 0                      0.762718   \n",
       "513                                 0                      0.794507   \n",
       "514                                 0                      0.706499   \n",
       "515                                 1                      0.017856   \n",
       "516                                 0                      0.796196   \n",
       "517                                -1                      0.028932   \n",
       "518                                 1                      0.258065   \n",
       "519                                 0                      0.880659   \n",
       "520                                 1                      0.034200   \n",
       "521                                 1                      0.023158   \n",
       "522                                 0                      0.750490   \n",
       "523                                 0                      0.817862   \n",
       "524                                 0                      0.726326   \n",
       "525                                 0                      0.797186   \n",
       "526                                 1                      0.000829   \n",
       "\n",
       "                          Processed Title  avg_sim_score  Success  \n",
       "0                                  Avatar       0.297514        1  \n",
       "1                           Avengers,-The       0.284754        1  \n",
       "2                          Men-in-Black-3       0.264265        0  \n",
       "3           Guardians-of-the-Galaxy-Vol-2       0.256726        1  \n",
       "4                                    2012       0.174552        0  \n",
       "5                    Terminator-Salvation       0.242028        0  \n",
       "6                              Mummy,-The       0.243462        0  \n",
       "7                       Great-Gatsby,-The       0.226589        0  \n",
       "8                           Thor-Ragnarok       0.193483        1  \n",
       "9                                      Up       0.259401        0  \n",
       "10            Snow-White-and-the-Huntsman       0.304867        0  \n",
       "11                           Interstellar       0.267558        0  \n",
       "12                   Beauty-and-the-Beast       0.216011        1  \n",
       "13                        Shrek-the-Third       0.329644        1  \n",
       "14                              Inception       0.357022        1  \n",
       "15                               Godzilla       0.219338        0  \n",
       "16   Curious-Case-of-Benjamin-Button,-The       0.252845        0  \n",
       "17         War-for-the-Planet-of-the-Apes       0.254866        0  \n",
       "18                                 Frozen       0.345820        1  \n",
       "19                               Zootopia       0.203930        1  \n",
       "20                   Matrix-Reloaded,-The       0.196067        1  \n",
       "21                                Hancock       0.285196        0  \n",
       "22                                   Thor       0.392277        0  \n",
       "23                X-Men-Origins-Wolverine       0.286076        0  \n",
       "24                        Angels-&-Demons       0.270651        0  \n",
       "25             How-to-Train-Your-Dragon-2       0.344482        0  \n",
       "26                              Star-Trek       0.152254        1  \n",
       "27                      Last-Samurai,-The       0.234878        0  \n",
       "28                             Spider-Man       0.230468        1  \n",
       "29                               Watchmen       0.255021        0  \n",
       "..                                    ...            ...      ...  \n",
       "497                          Visitor,-The       0.233579        1  \n",
       "498                           Cooler,-The       0.276665        1  \n",
       "499                            Four-Rooms       0.215945        0  \n",
       "500                     Gods-and-Monsters       0.230918        1  \n",
       "501                           Margin-Call       0.338230        0  \n",
       "502                                 Feast       0.173672        0  \n",
       "503                         Trainspotting       0.226502        1  \n",
       "504                French-Connection,-The       0.173180        1  \n",
       "505                     American-Splendor       0.270588        1  \n",
       "506                                Buried       0.244021        0  \n",
       "507           Beasts-of-the-Southern-Wild       0.397301        1  \n",
       "508                  I-Spit-on-Your-Grave       0.541255        0  \n",
       "509                        In-the-Bedroom       0.369024        1  \n",
       "510                 From-Here-to-Eternity       0.156483        1  \n",
       "511                              Repo-Man       0.263240        0  \n",
       "512                          Blood-Simple       0.212417        0  \n",
       "513                           Killing-Zoe       0.219068        0  \n",
       "514                         Believer,-The       0.197499        0  \n",
       "515                    Hebrew-Hammer,-The       0.262221        0  \n",
       "516                     Dear-White-People       0.271042        1  \n",
       "517                        Reservoir-Dogs       0.406188        1  \n",
       "518                           Taxi-Driver       0.219098        1  \n",
       "519                            Hellraiser       0.242416        1  \n",
       "520                         Sessions,-The       0.275139        1  \n",
       "521              Martha-Marcy-May-Marlene       0.357128        1  \n",
       "522                          Frozen-River       0.253777        1  \n",
       "523         Battle-of-Shaker-Heights,-The       0.231712        0  \n",
       "524                     Fruitvale-Station       0.214703        1  \n",
       "525                                 Brick       0.374844        1  \n",
       "526                 It-Happened-One-Night       0.334266        1  \n",
       "\n",
       "[527 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_id = X['Processed Title']\n",
    "X = ss.fit_transform(X.drop('Processed Title',axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mlp': MLPClassifier(random_state=0),\n",
    "        'dt': DecisionTreeClassifier(random_state=0),\n",
    "        'rf': RandomForestClassifier(random_state=0),\n",
    "        'svc': SVC(random_state=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    # Implement me\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler',StandardScaler()),('clf',clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['lr'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__hidden_layer_sizes': [10, 100, 200],\n",
    "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['mlp'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['dt'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__n_estimators': [2, 10, 30],\n",
    "               'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['rf'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "               'clf__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "               'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "# Implement me\n",
    "param_grids['svc'] = param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36238155, -0.374653  , -0.05975787, ..., -0.35228279,\n",
       "         0.48016592,  0.37777427],\n",
       "       [-0.42232269, -0.12792826,  0.26584147, ..., -0.35228279,\n",
       "         0.49930884,  0.20436729],\n",
       "       [-0.48682259,  2.5898864 , -0.1448543 , ..., -0.35228279,\n",
       "         0.52536775, -0.07406607],\n",
       "       ...,\n",
       "       [-0.60870943, -1.03979261, -0.45613979, ..., -0.35228279,\n",
       "         0.3213868 , -0.74758159],\n",
       "       [ 0.31213687, -0.1829286 , -0.80401902, ..., -0.35228279,\n",
       "         0.52836867,  1.42863646],\n",
       "       [ 0.83393843,  0.92807414, -0.97995141, ...,  1.96838006,\n",
       "        -1.79779358,  0.87720494]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/akartikay/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# The list of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# For each classifier\n",
    "for name in pipe_clfs.keys():\n",
    "    # GridSearchCV\n",
    "    # Implement me\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name], param_grid=param_grids[name], scoring='precision', n_jobs=-1, cv=StratifiedKFold(\n",
    "    n_splits=10, shuffle=True, random_state=10))\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, {'clf__C': 1, 'clf__gamma': 100, 'clf__kernel': 'rbf'}, <class 'sklearn.svm.classes.SVC'>]\n",
      "\n",
      "[0.6762785296350886, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 2}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.6058917704614446, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.6006057245405045, {'clf__activation': 'relu', 'clf__hidden_layer_sizes': 200}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n",
      "[0.546901213756852, {'clf__C': 0.0001, 'clf__multi_class': 'multinomial', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_]\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    # Print out [best_score_, best_params_, best_estimator_], where best_estimator_ is a pipeline\n",
    "    # Since we only print out the type of classifier of the pipeline\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "(439, 10) (439,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][-1].predict(X_test), rownames=['True'], colnames=['Predicted'])\n",
    "best_score_param_estimators[0][2].fit(X_train, y_train)\n",
    "print(best_score_param_estimators[0][2].score(X_test, y_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "best_score_param_estimators[0][2].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "True             \n",
       "0          95   0\n",
       "1          54  40"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][-1].predict(X_test), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ros, y_ros, test_size=0.3, random_state=0, stratify=y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = ros.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(628,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ros, y_ros, test_size=0.3, random_state=0, stratify=y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_param_estimators[0][-1].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1\n",
       "True             \n",
       "0          95   0\n",
       "1          57  37"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, best_score_param_estimators[0][-1].predict(X_test), rownames=['True'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
