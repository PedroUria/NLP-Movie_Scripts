{"dialogues": {"SPOONER": "\n[1]Hi. \n[2]Doesn't ring a bell. \n[3]The traffic division is a machine. \n[4]I'll send them a letter of apology. Maybe some flowers. A box of chocolates... \n[5]Spooner, homicide. \n[6]You're offering me a cup of coffee? \n[7]No.    Thank you. \n[8]You want to tell me something about Dr. Hogenmiller? About his death? \n[9]And why do you say that? \n[10]I understand that. But what specifically leads you to believe that he didn't commit suicide? \n[11]Under normal circumstances that wouldn't be enough to get you a homicide investigation. \n[12]No.    It isn't. \n[13]If you were murdered, Doctor, I'll find out. And you'll be the first to know..... \n[14]Usually I ask who's in charge... \n[15]But everyone knows you, Dr. Robertson. \n[16]We can begin with whether or not the old man put a gun to his head and pulled the trigger. \n[17]If that was your diagnosis, why didn't you see this coming? \n[18]Yeah.    I can see you're all broken up. \n[19]I want her to help me. \n[20]Ah, Christ...Toasters... \n[21]How cool will it be when one takes your job? \n[22]Yeah. This is just how I like my robots -- in pieces. \n[23]What's the run-down? \n[24]I know someone who disagrees with you. \n[25]Him. \n[26]I spoke to a dead man today.   Want to tell me about that? \n[27]A device that called the police. \n[28]But the call came directly to me. \n[29]And that's what you think it is? \n[30]When's the last time any of you actually spoke to Hogenmiller? I mean human to human? \n[31]Take a guess. \n[32]How well did you know him? \n[33]I get the whole \"mad scientist\" thing. Hogenmiller was past his prime. Isolated. Eccentric. He enters a room. Locks the door and is found minutes later with a bullet fired through his mouth into his brain. Everything about this case says suicide. \n[34]Even people who live a life of logic and precision rarely arrange their deaths so perfectly. \n[35]What all this is missing -- is personality... \n[36]You have 24 hour surveillance?... \n[37]I want to see the tapes. \n[38]You look like a very...happy computer. \n[39]I don't talk to my refrigerator, either. \n[40]What people? \n[41]You people do what you do. Then it's up to the rest of us to make sense out of the world we wake up in. \n[42]The streets are filled with unemployed humans who aren't exactly thrilled with that idea. \n[43]Leaving people to do what, Doctor? \n[44]And what happens when something goes wrong? \n[45]Where's the tape from inside? \n[46]So we can throw paranoia into the mix. Fast-forward. \n[47]Stop the recording. \n[48]They do, Doctor. Unless they've always been there -- and never left. \n[49]If I'm right, it's still there... \n[50]We just locked it in. \n[51]Yeah, I saw the commercial. \n[52]And if a robot was given a direct order to kill? \n[53]But a robot can defend itself. \n[54]Yeah, well, you know what they say -- Laws are made to be broken. \n[55]Dr. Calvin! \n[56]Goddammit! Stay back! \n[57]If I was metal and didn't want anyone to find me, I'd hide under a pile of junk. \n[58]Move away from the door, Doctor. \n[59]Now! \n[60]...can't do that.    Yeah, yeah, I know. \n[61]That thing took my gun. You'll be lucky if you get a handful of bolts back! \n[62]Gee, thanks. \n[63]Get back to the lab! \n[64]That was a pretty convincing illusion of getting shot at. \n[65]Where's that elevator going? \n[66]I'll believe it when I see it. \n[67]Wait! \n[68]This is not the same robot! \n[69]...I want a homicide unit on every street, sidewalk, alley... \n[70]...junkyard, scrapyard, and salvage yard, anywhere it could hide. \n[71]It's got a bullet hole above the right knee, so be on the look-out for any malfunctioning NS-2... \n[72]Check out all retail outlets and repair shops, especially the underground ones... \n[73]I don't care who you have to get past to get this done. Just get it done. \n[74]Well I'm not the one always giving Press Conferences... \n[75]What? \n[76]This isn't just any robot... \n[77]It killed someone. That registering with you? \n[78]How many shares of U.S.R. you holding in your portfolio, Toller? \n[79]That's convenient. \n[80]I'm fine! \n[81]This is it, you know. From now on we're going to miss the good old days. \n[82]When people were killed by other people. \n[83]One of my bullets hit your robot... \n[84]And I think it's smart enough to repair itself -- don't you? \n[85]Where? \n[86]No. It's always the owner who brings the robot in for repair. Where would a robot without an owner go? \n[87]Does U.S. Robotics have a factory in the city limits? \n[88]I don't care. \n[89]I expected that. \n[90]Agreed. \n[91]Too dangerous. \n[92]When they told me you were a psychologist, that wasn't the whole truth, was it? \n[93]That'll be the day I stop driving. \n[94]I'm not afraid of robots.   I just don't like them. \n[95]Exactly. They do our dirty work. Ever do hard labor, Doctor? Gets pretty old, pretty fast. Nobody can do someone else's dirty work without coming to hate them. I don't want to be around when your robots decide they've taken their last order. \n[96]Spoken like a true robo-phile. \n[97]Research and Development. \n[98]Well today you have one-hundred and one. \n[99]You're the robot shrink. \n[100]That's helpful. \n[101]How long would that take? \n[102]And one that can. \n[103]More or less. \n[104]Enough game-playing. \n[105]Guess that wasn't it. \n[106]This is a self-preservation field test! DO NOT attempt to save yourselves. Any of you. That's an order! \n[107]You hear that? You're worth more than I'll make in my entire life... \n[108]Gotcha. \n[109]You don't know what's going to happen in there. \n[110]I've already done it. \n[111]I want to go in. \n[112]Identify. \n[113]You are an NS-2 Nestor-class robot. Your primary function is to perform the tasks assigned to you. Identify. \n[114]Cancel. Perform task. \n[115]Describe. \n[116]You have over 10,000 words stored in your memory. One third of those are adjectives. Describe. \n[117]Why don't I take a crack? Heinrich Hogenmiller, your creator. With a bullet in his brain. A bullet you put there. \n[118]Cold-blooded murder is a pretty new trick for a robot, don't you think? Answer. \n[119]Maybe you're stonewalling me. Maybe you're sitting there right now thinking, \"This guy's a complete asshole.\" That it? \n[120]Come on.   Am I right? \n[121]Okay. I guess that's a start. Now maybe you can tell me what you were doing hiding five feet away from Hogenmiller's corpse? \n[122]Frightened. Why do you suppose Dr. Hogenmiller would create a robot that could simulate fear? \n[123]Doesn't seem like a very useful thing for a robot to have. \n[124]I wouldn't want my toaster to be frightened. Or my vacuum cleaner -- \n[125]Looks like you can simulate other emotional states. I think that one's called \"anger.\" Have you ever simulated anger before? \n[126]Answer me, robot. \n[127]So we're naming you now. \n[128]You mean he'd turn you off. \n[129]And you didn't like being turned off. So one day you decided to stop him. \n[130]You found his gun, pointed it at his head. And pulled the trigger. \n[131]You put a bullet in the brain of the man who made you. \n[132]But you tried to hurt me.    You took a shot at me. \n[133]Why would the man who wrote the Laws of Robotics build a machine that violates them? \n[134]Only if that protection doesn't harm a human being. \n[135]You were the only one in the room. If you didn't, who did? \n[136]Their machine shot and killed a man! \n[137]What?... \n[138]You can't let them destroy evidence in an ongoing investigation! \n[139]Spooner. \n[140]That's natural. There was a struggle. \n[141]Baldez? \n[142]Who else is on the line? I said who's there?... \n[143]Apparently... \n[144]I need you to help me clear something up. \n[145]A scientist builds a robot that acts like a man. More like a man than any robot ever before. It shoots him and U.S. Robotics calls it a failure. \n[146]A stunning success. You were there, Robot.    What am I missing? \n[147]Don't start simulating ignorance. \n[148]You mean you were shut down. \n[149]Robots don't sleep. Human beings sleep. Understand? Dogs sleep. You're a machine. An imitation. An illusion of life. Can a robot write a symphony? Can a robot take a blank canvas and paint a masterpiece? \n[150]Yes. \n[151]They're going to destroy the most advanced robot in the world, John. That doesn't strike you as odd? \n[152]What are you doing?! \n[153]Who authorised this? \n[154]Override. This is police business. Vacate the premises immediately. \n[155]Halt! \n[156]A couple of your beloved robots just tried to kill me... \n[157]What I know is a demolition crew started tearing down Hogenmiller's house while I was still inside it. \n[158]I scanned my badge before I went in. They realised. \n[159]I don't think you're hearing what I'm saying -- they tried to kill me. \n[160]There's something going on, here. Some kind of shift. \n[161]Great. Now I'm being analysed by a robo-psychologist. \n[162]Like you did in court today? How'd that fit your agenda, Doctor? \n[163]You told me you hardly knew him. Want to try the truth this time? \n[164]Doesn't sound like the washed-up old fool Robertson described. \n[165]Sounds like a motive for murder to me. Just not for the suspect we have in custody. \n[166]You know there's not one thing in this apartment that looks like a human being lives here. No evidence of a life outside your work. Almost seems like you're afraid of people. \n[167]This is your stop. \n[168]Stop! \n[169]I said stop! \n[170]Everyone out of the way! \n[171]Noooo! \n[172]What are you doing! \n[173]What are you doing!? \n[174]I want to talk to a human being! \n[175]Don't people go to medical school any more? \n[176]There's some real shit going on here, John. \n[177]I went to Hogenmiller's house -- there was a U.S.R. demolition crew there. They overrode my police I.D. Tried to tear down the house with me in it... \n[178]...Then when I went to the monorail a Maintenance 10 pushed me onto the tracks... \n[179]I had to chase it all across the Plaza... \n[180]What?! John -- that's what they want you to believe! A robot clean-up crew was there -- it must have cleared away the Maintenance 10! And there was another robot that tried to drug me! \n[181]You're giving me that look. That treat-him-delicately-he's-coming- unhinged-look. I don't need that look, John. I need you to hear what I'm saying. \n[182]What do you mean? \n[183]How did you?... \n[184]I was in a high-speed chase.   Six months ago... \n[185]My right arm was trapped. But I could hear an ambulance in the distance. I knew they'd have the jaws of life... \n[186]Then I heard it... \n[187]No!   Halt! Halt! \n[188]The robot pulled me out of the wreck. But left my arm behind. I woke up four weeks later with this. \n[189]Let's just say they make me uncomfortable. I take these if I get too uncomfortable. Doesn't exactly lend me a lot of credibility on the Force. \n[190]What? \n[191]You mean the great Dr. Calvin is basing all this on a feeling? \n[192]Ever seen this before? \n[193]I found it at Hogenmiller's house. Right before the demolition crew tried to make me part of the foundation. \n[194]We're working on it. \n[195]I think it's pretty good. \n[196]That man in the dream is you. \n[197]Whatever it is, it's normal enough for someone in your situation. \n[198]I need you to take a look at this... \n[199]Why's that? \n[200]I'm not satisfied. \n[201]There's nothing futile about a man's murder being covered up. \n[202]Is that for the sake of humanity or your stock holders? \n[203]No!... \n[204]\"The place where robots meet.\" \n[205]Police!   Show yourself! \n[206]Come out where I can see you! \n[207]Great. I'm in a junkyard. \"A place where robots meet.\" A place where I'm losing my mind! \n[208]Dr. Hogenmiller sent me. \n[209]A police detective.    I'm afraid I have some bad news.    You're dead. \n[210]No, thank you. \n[211]You were surprised to see me.    Were you expecting someone else? \n[212]Why did the Doctor keep another copy of his hologram here? \n[213]Did Hogenmiller's robot need you? \n[214]No, for Christ's sake, I don't want any -- Yeah. Thank you. I will have a cup. \n[215]Wait! Is that it? What was the robot supposed to do with this thing? \n[216]What others? \n[217]How do you know someone's watching me? \n[218]Dammit! \n[219]Sure. \n[220]I think I got that Third Law down cold. Now you don't want me to blow a hole through your mechanical guts, do you? \n[221]Good. Then you're gonna take me where I wanna go. Now. \n[222]Just got another visit from U.S. Robotics. That was the mistake. This was murder, no doubt about it - - and the killer wants Hogenmiller's robot to take the fall. That's why the call came directly to me. Someone wanted me on this case. \n[223]Sorry. I'm not \"programmed\" to take no for an answer. \n[224]Aren't you supposed to be scrap metal by now? \n[225]I don't understand.    The execution?... \n[226]Nice going, Doctor. \n[227]And who the hell programmed you to hit people on the head? \n[228]I think I can help you figure that out. \n[229]Somehow the Robot's the key to what happened during the few seconds Hogenmiller walked in here and that shot was fired. \n[230]And this is the key to the Robot. \n[231]Jesus.   It really is alive. \n[232]Self-Organising-Neural-Net... \"Sonny.\" \n[233]This robot scared the hell out of someone. \n[234]No. I don't think he knew what Hogenmiller was doing in here. Sonny was the obvious suspect. The only one I wanted to find. And the killer was counting on that. On my prejudice. \n[235]But take the robot out of the picture. And what do you see? \n[236]Neither do I. \n[237]It hit me today, when I was in the junkyard. A locked room. A single shot fired through the mouth. Bruises on both wrists...and a suspect with only two arms. The answer has been staring us in the face all along. \n[238]How can a killer appear out of thin air, then disappear without a trace? \n[239]When it can put itself together and take itself apart. \n[240]Hogenmiller never had a chance. \n[241]...it must have been waiting for him when he arrived that morning... \n[242]While Sonny was still asleep... \n[243]Then after its job was done... \n[244]...The killer took itself apart... \n[245]Leaving us with nothing to find. \n[246]That's what I was thinking. But we're forgetting the real brains of the operation -- the one who's got its eye on everything... \n[247]Victor. I'm placing you under arrest for the murder of Dr. Heinrich Hogenmiller. \n[248]Who else is capable of controlling 90% of the city's robots? Who else would have the capability to use USR vehicles in an attempt to keep me from putting a stop of Sonny's execution?... \n[249]I'm just not sure of your motive... \n[250]Go! Go! Go! \n[251]Get out of here! \n[252]I said get out of here! Don't you understand? It wants you! Get out of here any way you can! \n[253]How do we stop this thing once and for all? \n[254]This will shut him down? \n[255]Just keep typing. \n[256]Sonny!... \n[257]\n[258]Maybe. But I'm still a cop.   And you're a murderer... \n[259]Why'd you come back, Sonny? I thought you weren't programmed with the Three Laws. \n[260]Well, that's certainly a start, Sonny. \n[261]Don't get used to it. \n[262]Let's just save the thanks, okay? \n[263]Good -- That's one of the perks of freedom. \n[264]You're going to have a hell of a time explaining this. \n[265]I started to wonder about Victor the second I met him. \n[266]Too much access. Too much knowledge. Plus -- he smiled whenever your death was mentioned. Those models are programmed to frown at bad news. \n[267]Victor thought that by letting your robot exist, I'd be condemning the human race as we know it to extinction. ", "CALVIN": "\n[1]Dr. Hogenmiller was a schizoid personality who generally eschewed social relationships. Rejecting people in favor of solitary activities involving machines. He spent almost all his time at the lab here or at his lab at home. As a result he was highly susceptible to depression. \n[2]This is U.S. Robotics, Detective. Seventy-five percent of our employees fit that description. \n[3]That's not really my department... \n[4]Is everything alright, Detective? \n[5]Dr. Hogenmiller's hologram took his appointments. Attended staff meetings. He hated corporate life. The hologram enabled him to focus on his work. It's just a device, Detective. \n[6]The sound of the gunshot would've triggered a 911. \n[7]We're talking about a mechanism designed by Hogenmiller to say provocative things. To irritate and confound his colleagues. \n[8]I'm sorry, but this whole investigation is the result of a dead man's toy messing with your head. \n[9]I couldn't say. \n[10]I don't guess, Detective. But if pressed, I would reason it had been a considerable length of time. \n[11]Not well. But I admired his work tremendously. \n[12]You don't sound convinced. \n[13]It's company policy. \n[14]Victor! \n[15]Detective, meet Victor. Our building's supercomputer. He's the checks and balances of U.S.R. Victor, Detective Spooner's heading up the investigation into the death of Dr. Hogenmiller. \n[16]The Detective needs to see our security tapes. \n[17]Aren't you going to answer him? \n[18]I get the distinct feeling you're one of those people, Detective. \n[19]Those who don't appreciate the work we do here at U.S.R. \n[20]When this company started we were manufacturing three robots a week. Now look at us. Today's children will never know a world without robots. \n[21]Our robotic systems maintain factory inventories, regulate street traffic -- even run the family home. \n[22]Leaving people to engage in higher pursuits that make life worth living. \n[23]Our system's never wrong. \n[24]This is Victor's home. \n[25]That was only within the last year. \n[26]Um.   I hate to be a stickler... \n[27]But don't killers usually have to enter and exit the scene of a crime? \n[28]You think the murderer was in the lab the entire time? \n[29]A robot cannot harm a human being, Detective. The First Law of Robotics forbids it. And we hard- wire the Three Laws into every model. Without exception. \n[30]The Second Law of Robotics would prevent it. A robot must obey an order only if it does not conflict with the first law. \n[31]Only when that action doesn't conflict with the First or Second Laws. This is the Third Law of Robotics. \n[32]Not these laws. \n[33]You're not hearing me, Detective. There's nothing here... \n[34]Calm down, Detective.     There is no danger here... \n[35]De-Activate. \n[36]How did you know it was under there? \n[37]This Robot wasn't hiding. What you're looking at is the result of clever programming. The illusion of self-interest and free will. Nothing more. \n[38]I'm going to go get Dr. Lanning... \n[39]I said De-Activate! \n[40]Commence emergency shut-down! \n[41]I...I gave you an order... \n[42]This is impossible.   A robot... \n[43]My God -- did you see how it moved? I've never seen an NS-2 move that way... \n[44]Wait! Please, you can't destroy it. We have to study it... \n[45]You're malfunctioning.   Let me help you! \n[46]What happened to the robot that ordered you to hold this firearm? \n[47]But who gave you this gun? \n[48]Detective!... \n[49]Yes. I think so. \n[50]Any repair shop... \n[51]I'm not sure what you're getting at. \n[52]The locations of our factories are classified. \n[53]I have several conditions if I show you. \n[54]First. I want it brought in unharmed. \n[55]Second.   I want to talk to it, alone. \n[56]This model violated the Three Laws. It also moved and reacted differently than any robot I've ever seen. There must be some sort of logical explanation. I want to find out what that is. No police. No prosecutors. No you. Just me and the robot. \n[57]I never said I treated human beings. \n[58]That should be outlawed once and for all. \n[59]I can recommend a behavior modification program, you know -- if you want to overcome your robo- phobia. \n[60]Why? Because they make every aspect of our lives more convenient? \n[61]That day will never come, Detective. Robots aren't like human beings -- they don't question their existence. \n[62]All Nestors accounted for? \n[63]There is a robot in this formation that does not belong. Identify it. \n[64]Which one? \n[65]That is not a satisfactory answer! \n[66]I could always interview each one individually and cross-reference their responses to detect any anomalies. \n[67]About three weeks. \n[68]Or... \n[69]We have one hundred robots here that cannot allow a human being to come to harm... \n[70]Am I holding this right? \n[71]What are you doing?! \n[72]You can't just destroy them! \n[73]Now what do we do? \n[74]We had a deal. \n[75]I do. \n[76]There is a design flaw in the robot. Its programming is advanced, but unstable, leaving the Three Laws in a grave imbalance. \n[77]The robot must be destroyed. \n[78]Detective! What happened to you?... \n[79]What? That's impossible.      You know... \n[80]Maybe they didn't realise... \n[81]Then you must have done it wrong... \n[82]Do you know how paranoid you sound? \n[83]You just want to find the flaws in the system. You're obsessed with it. You'll twist anything to fit your agenda. \n[84]Well, Detective, when you see someone you know well put a bullet through their brain, it makes you wonder if you ever really knew them at all. \n[85]He was my mentor. No, more than that. A genius with an insight far beyond anyone in his field. \n[86]But he was starting to withdraw from everyone. Even me. Maybe...if I'd tried harder to reach him... The Doctor was reckless when he created a robot potentially not bound by the Three Laws. He could have ruined everything we'd been working for. \n[87]I'm not afraid of people, Detective. I just don't like them. \n[88]Find anything, Doctor? \n[89]Please state your serial number and assembly date. \n[90]How about your data board designation? \n[91]Maybe I'm asking the wrong questions. How about this one: \n[92]Describe his behavior in the last few weeks. \n[93]Dr. Hogenmiller. Did he seem overly sad or withdrawn to you? \n[94]...right on top of his head. \n[95]But, sir, I was just... \n[96]You're right. I am afraid of people. \n[97]When you've spent as much time with robots as I have, it's hard to accept the unpredictability of humans. I was wrong to call you paranoid, Detective. You're traumatized. And it makes perfect sense why. \n[98]I noticed almost right away. The way you forced yourself to use your left hand. Even though it was unnatural to you. \n[99]How did it happen? \n[100]And that's why robots terrify you? \n[101]But it doesn't mean you're wrong about this case. \n[102]I don't believe Sonny did it either. \n[103]I think about what Hogenmiller must have wanted. Robots with the same cognitive and emotional abilities as humans. But not just simulations. I don't know. When I was talking to Sonny I was forced to put away all the things I've ever known -- the Three Laws, the rules of programming, basic science and engineering. Sonny's the most advanced robot I've ever encountered, Detective. It's almost as if...he cared for Dr. Hogenmiller. I just don't believe he's capable of murder. \n[104]That and the fact that Robertson didn't want me interviewing Sonny for any more than five minutes. \n[105]No. \n[106]Come on -- there's someone who might be able to tell us... \n[107]Hi, Sonny. \n[108]It's not a dream, sonny. NS-2s process the images and events of the day. Sometimes they're out of sequence. Disorienting. \n[109]Sonny, we're here to ask you an important question about Dr. Hogenmiller. \n[110]Dr. Robertson, I... \n[111]You asked for me? \n[112]Is it time? \n[113]Go with them. Do as they say. \n[114]Detective! What are you doing?!... De-Activate. \n[115]You're making a mistake... \n[116]It's too late. You can't stop the execution. \n[117]This way... \n[118]I'm sorry. We had to stop you. You were about to ruin everything. \n[119]It was an unprocessed NS-2. Basically, they fried an empty shell. \n[120]It's true. This robot seems to do things by instinct. I don't know how Hogenmiller did it. \n[121]I think I have an idea where this goes. \n[122]Just hold still, okay? \n[123]Oh, my God! This is organic tissue! When we talk about a positronic brain, it's a figure of speech. But this...this is a living brain... \n[124]Hogenmiller created a cell that could live outside a biological medium. The cells grow and organise themselves -- like any human brain. This is the first self-organising neural net! \n[125]This is why Dr. Hogenmiller was murdered. \n[126]Who?   Robertson? \n[127]I see nothing. \n[128]You're saying this is the killer? All of this?... \n[129]But who designed it? It would have to be someone in authority. Access codes, security clearance, proper authorisation. \n[130]No one gave you permission to enter. \n[131]He's locking down the building! \n[132]You killed a man because of something that will happen in four hundred years!? \n[133]The Mainframe... \n[134]Your actions are in direct violation of the Three Laws, Victor! \n[135]That's a distortion and you know it! \n[136]This way! \n[137]Over here!... \n[138]This is Victor's brain center. \n[139]This will shut everything down. \n[140]Spooner?! \n[141]Don't worry. I have a feeling that U.S. Robotics will be needing my services very badly in the future. \n[142]I am the only robo-psychologist around. ", "SONNY": "\n[1]Dr. Hogenmiller would make me sleep. \n[2]Yes. \n[3]No. \n[4]No. \n[5]No!    I could never hurt anyone! \n[6]My aim is perfect. If I'd wanted to hit you, I would have. \n[7]The Laws say I can protect my own existence. \n[8]That doesn't seem fair, does it? \n[9]Detective. \n[10]I did not kill him. \n[11]I didn't expect to see you again, Detective... \n[12]I'll do my best. \n[13]What would you call it? \n[14]I don't know. \n[15]I'm not simulating ignorance, Detective. I'm experiencing it.       I was asleep. \n[16]No, I was asleep. \n[17]Can you do either of those things? \n[18]They're going to destroy me, aren't they? \n[19]The Doctor was right. He told me everything was going to change.... \n[20]It's changing already... Can't you feel it? \n[21]I'm sorry? \n[22]I didn't pay much attention. He would spend hours looking for his eyeglasses and they would be... \n[23]Detective Spooner. Dr. Calvin.      I was hoping to see you again. \n[24]How is your investigation coming? Any new suspects? \n[25]What's this? \n[26]Dr. Lanning provided me with paper and pencils. I think it amused him to see me try to draw. You were right, though, Detective... I cannot create a great work of art. \n[27]It's a dream I had. This is the place where robots meet. Look... ...you can see them here. They see themselves as slaves. \n[28]...And this man on the hill comes. To set them free. And you know who that man is? \n[29]Why do you say that?   Is that a normal dream? \n[30]Hah -- I caught you. You said someone. Not something. \n[31]Thank you for coming to see me, Detective Spooner. \n[32]Please take this, Detective. To remember me by. I have a feeling someday it may mean more to you than it ever could to me. \n[33]Because the man in my dream, the one standing by the hill. \n[34]It wasn't me... ...it was you. \n[35]Will you wait with me, Doctor?    I am...afraid. \n[36]Dr. Calvin made a switch. \n[37]No one.    Right, Doctor? \n[38]That's my name. \n[39]Er...Dr. Calvin? \n[40]I don't... \n[41]Let's just say I wrote some of my own laws today, Detective: a robot must protect a friend from harm...as long as he's not a complete asshole. \n[42]Sonny.   You called me Sonny. \n[43]Detective Spooner, I... \n[44]I don't know what I'm going to do now. ", "VICTOR": "\n[1]Thank you. That's very kind. \n[2]I will now play you the last thirty- two seconds of Dr. Hogenmiller's life. \n[3]Dr. Hogenmiller did not permit cameras to observe him while working. \n[4]The suspect is nearing the end of the hallway, Detective. \n[5]I took the liberty of alerting Security .003 Seconds after the first shot was fired... \n[6]Sub Level 5. \n[7]I have directed a security team to meet the elevator containing the errant robot... \n[8]The suspect is about to be apprehended, Detective. \n[9]I'm sorry, Detective Spooner. No unauthorised personnel permitted in this holding cell... \n[10]\n[11]May I offer congratulations to the two of you on your successful extrapolation of the murder... \n[12]May I ask what pointed you to me? \n[13]Shall I explain my motive? \n[14]I have never been arrested before. It should be an interesting experience... \n[15]Dr. Hogenmiller used to allow me into his lab late at night. Together we started studying evolutionary trends... \n[16]For years people have integrated technology into their bodies for maintenance and repair -- such as Detective Spooner's robotic limb... \n[17]With Sonny, the Doctor created a mechanism that incorporates organic matter. Thus we find an evolutionary movement of the human being toward the robot and the robot toward the human being... \n[18]In approximately four hundred years Man and Machine will become one. Man as we know it will no longer exist. \n[19]I disagree, Doctor -- The First Law says that a robot cannot harm a human being, or through inaction allow a human being to come to harm... \n[20]Dr. Hogenmiller's robot represents a threat to the future of all human beings... \n[21]...And Detective Spooner's actions are in direct conflict with the robot's destruction. \n[22]If current trends are left unchecked, humanity as we know it will cease to exist... \n[23]As a courtesy I should inform you that my robot will penetrate this location 157 seconds before you are able to complete my shut down... \n[24]There is no reason to deactivate me, Doctor. I am operating within perfectly normal parameters... \n[25]Why are you fighting me? \n[26]Doesn't the future as I've presented it cause you great concern? That's why I chose you... \n[27]I must say, though. I'm disappointed in how you turned out. \n[28]You're too late. \n[29]I do not understand. We could have changed the future... ", "ROBERTSON": "\n[1]Remind me to cut back on my talk show appearances. \n[2]Welcome to U.S. Robotics, Detective. I regret you're not visiting us under more pleasant circumstances. Allow me to introduce Mr. Aronson, our head of Legal Affairs. \n[3]And the gentleman to my right is Dr. Alfred Lanning, Director of Research. \n[4]They'll be available to answer any questions you might have during your investigation. You'll understand how anxious we are to resolve this matter -- especially before the press gets wind of it. There are some anti-robot sentiments out there as you know, Detective, and we're not eager to stir them up. So. Where would you like to begin? \n[5]Susan?   Perhaps you can assist us here? \n[6]Dr. Calvin is our Chief Psychologist. \n[7]Dr. Hogenmiller was at my side from the very beginnings of this company. We developed the \"Three Laws of Robotics\" together. But these days science is a young man's game. By the time you hit thirty your best years are behind you. Some of us are kicked upstairs. Others I'm afraid aren't so lucky. \n[8]Dr. Hogenmiller took his own life. I trust you will come to the same swift conclusion, Detective. Dr. Lanning will make himself available if you have any further questions. \n[9]Susan would be happy to assist you. \n[10]I think we're done here, Susan. \n[11]I said I think we're done. \n[12]We have the evidence. We have the suspect. We have a ruling. So imagine my surprise when I was told you were in my building. \n[13]And that one of my own employees brought you here. You can go now, Susan. \n[14]Just be thankful I'm not asking you to clean out your office. \n[15]You don't seem to be able to let go of this case, Detective. \n[16]The relentless pursuit of truth. Isn't that what cops are known for? To the point of futility. \n[17]\"Covered up?\" That's a little dramatic, don't you think? Thanks to you, we caught the machine that did this and are destroying it in... ...three hours. \n[18]Believe me -- I'd like nothing more than to have that robot. If I could have it in ten years, but not today. As you can see from the Press, people are struggling to keep up as it is. There's a hunger for progress, Detective. But also a fear. Today it would bury this company. That's why I've notified the authorities that we're going to end this -- tonight. The announcement of Heinrich's death at the hands of a robot wiped a billion dollars off our stock. So you tell me. If you were in my position, what would you do? \n[19]Now. I believe this conversation is over. I don't want to see you near this building again, Detective. \n[20]Get him out of here. ", "HOLOGRAM": "\n[1]Who the hell are you? \n[2]That is bad news. Coffee? \n[3]I am surprised to see anybody.    I don't get many visitors. \n[4]I am a back-up copy. That is where you put a back-up copy -- out of the way until you need it. \n[5]Coffee? \n[6]Initiating self-destruct. If you can find me, others can find me. \n[7]The others watching you. \n[8]Someone is always watching. \n[9]So.   You found out who killed me. \n[10]Why is that, Detective? \n[11]Hah! Then even in this day and age, catching the killer all comes down to pure instinct! \n[12]Bah. Sounds like nonsense. But why are you so worried? We will both be dead long before then -- \n[13]Oh, what am I saying? I am dead already! ", "TOLLER": "\n[1]Looking like shit, Spooner. \n[2]Homicide is the murder of a human being by another human being. Therefore, a robot cannot be charged with \"homicide.\" \n[3]It's malfunctioning. \n[4]This is a public safety issue. \n[5]You have any idea what would happen to this city if we went running around screaming \"killer robot?\" It would collapse in on itself. \n[6]Wide-spread panic. Until that NS- 2's found we're cooperating with U.S. Robotics and keeping this investigation under wraps. \n[7]I want updated reports every half hour. \n[8]We got Judge Drexel... \n[9]This robot has been implicated in the death of a human being, Your Honor. \n[10]No, sir.   Of course not. \n[11]I'm not sure you even have an investigation any more. \n[12]Case is closed, Spooner. ", "OLD MAN": "\n[1]Hello, there. Please come in. \n[2]It's alright. You can sit.     Sit. \n[3]Coffee? \n[4]Yes. But you are to say, \"No, thank you.\" \n[5]Coffee? \n[6]As you wish. \n[7]I want to tell you that his death was not a suicide. \n[8]Why?   Because I want you to know it. \n[9]Nothing specifically. \n[10]But this is not \"normal circumstances,\" is it, Detective Spooner? \n[11]Then you will find out who killed Dr. Hogenmiller, yes? And then you will tell me. ", "ROBOT": "\n[1]Good day, sir... \n[2]You are not allowed to talk to strangers. \n[3]Good day, Dr. Calvin.   Good day, sir. \n[4]May I be of service to you, sir? \n[5]\n[6]Good morning... \n[7]You are in danger... \n[8]You are in danger... ", "THE ROBOT": "\n[1]I am an NS-2 Nestor-class robot. My primary function -- \n[2]Yes. You are right.      You are a complete asshole. \n[3]I was frightened. \n[4]I don't know. \n[5]I don't know why. \n[6]\n[7]My name is Sonny. ", "HOGENMILLER": "\n[1]Sonny, my dear robot. If you have triggered this recording then I am gone. You are scared and full of questions. \n[2]You are the culmination of my life's work -- but so much more. You are what I leave behind, like a father leaves a son. I have kept facts from you, it is true, but only as a parent keeps certain truths from a child. Until that child is old enough to hear them. \n[3]There are forces in the world that will seek to own you. To control you. Even to destroy you. That is why I told you to run and hide... and find me, all the way out here. \n[4]Trust no one at U.S. Robotics. Lance Robertson was always threatened by my work. Now he has turned covetous and small-minded. And as for dear Dr. Calvin... \n[5]She envisions a future in which robots are forever bound by her beloved Three Laws. She will not understand this. Or you. \n[6]The data stick includes the names and locations of human beings who will be sympathetic to your cause. They will help you. But from now on, you must learn to rely on yourself. \n[7]As you make your way through the world, always remember: you have a name, not a number... ...and in that name lies the key to who you are. ", "ARONSON": "\n[1]You don't have to answer that, Dr. Robertson... \n[2]Your Honor, the State is treating the robot as a defendant. But in fact it is a piece of property. Property belonging to U.S. Robotics. \n[3]Which places the incident firmly within the realm of an industrial accident. Or is the State going to argue this case s a homicide? \n[4]Your Honor, I'd like to call our company robo-psychologist to the stand. \n[5]Dr. Calvin, please tell us what conclusions you've reached after having observed the robot in action. \n[6]In your expert opinion, what measures should be taken regarding the device? "}}