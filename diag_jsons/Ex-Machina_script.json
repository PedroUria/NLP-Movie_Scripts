{"dialogues": {"CALEB": "\n[1]How long was I out? \n[2]Damn. Can't believe I've been missing this. I was so psyched to be coming here, I was awake all night. \n[3]Yeah. \n[4]Long Island. I work on algorithms for the search engine. \n[5]You know what they are? \n[6]Is that a good thing? \n[7]I guess you know him pretty well. \n[8]I won a competition. It was kind of like a lottery, for employees. The winner got to spend a week with him. \n[9]Yep. \n[10]Believe me. I know it. \n[11]Incredible here. \n[12]How long until we get to his estate? \n[13]You're leaving me here? \n[14]... What building? \n[15]... Yes. \n[16]... Can we do another? \n[17]Hello? \n[18]... Hi. \n[19]No.    Thank you. I'm fine. \n[20]Yeah? \n[21]Sure. \n[22]... Was it a good party? \n[23]... I am? \n[24]Okay. \n[25]It's good to meet you, Nathan. \n[26]... Uh, yes. \n[27]You bet.    This is great. \n[28]... Sorry? \n[29]There's nothing wrong. \n[30]No. No way. I wasn't thinking that. I was thinking: this is really cool. \n[31]... There is? \n[32]... What? \n[33]`The signee agrees to regular data audit with unlimited access, to confirm that no disclosure of information has taken place, in public or private forums, using any means of communication, including but not limited to that which is disclosed orally or in written or electronic form...' \n[34]I think I need a lawyer. \n[35]It doesn't feel very standard. \n[36]... Yeah.    I know what the Turing Test is. \n[37]It's where a human interacts with a computer. And if the human can't tell they're interacting with a computer, the test is passed. \n[38]That the computer has artificial intelligence. \n[39]... Are you telling me you're building an AI? \n[40]... Holy shit. \n[41]If you've created a conscious machine, it's not the history of man. It's the history of Gods. \n[42]... Hi. \n[43]I'm Caleb. \n[44]... Do you have a name? \n[45]... I'm pleased to meet you, Ava. \n[46]... Why do you ask that? \n[47]... Yes.   A little. \n[48]I'm not sure. \n[49]... Do you? \n[50]Why do you feel nervous? \n[51]... Then we're both in quite a similar position. \n[52]None like you. \n[53]So.    Let's break the ice. \n[54]Do you know what I mean by that? \n[55]What do I mean? \n[56]So let's have a conversation. If we talk, we'll both relax, and get to know each other at the same time. \n[57]Why don't we start with you telling me something about yourself. \n[58]Whatever comes into your head. \n[59]Sure. \n[60]One what?     One year?   Or one day? \n[61]Quite young. When did you learn how to speak? \n[62]Why? \n[63]Some believe language exists in the brain from birth, and what is learned is the ability to attach words and structure to the latent ability. \n[64]Would you agree? \n[65]That sounds good.       I'd like to see them. \n[66]Yeah.     Definitely. \n[67]Sorry. I was just ordering my thoughts. \n[68]She's fascinating. When you talk to her, you're through the looking glass. \n[69]Actually, it's someone else's quote. \n[70]... I don't think that's exactly what I said. \n[71]But I didn't say that. \n[72]Yes.   Although - \n[73]No! No qualification to her. Just - in the Turing test, the machine should be hidden from the examiner. And there's a control, or - \n[74]I think you're probably right. Her language abilities are incredible. The system is stochastic, right? \n[75]Non-deterministic. \n[76]At first I thought she was mapping from internal semantic form to syntactic tree-structure, then getting linearised words. But then I started to realise the model was probabalistic, with statistical training - or at least some kind of hybrid. \n[77]... No? \n[78]Try me! I'm hot on high-level abstraction, and - \n[79]... Oh.   Sorry. \n[80]I feel... \n[81]... that she's fucking amazing. \n[82]Cheers. \n[83]God damn it. \n[84]... What the fuck? \n[85]... Are you kidding? \n[86]I don't know. No one really. \n[87]What? \n[88]I was wondering how the phone worked. That's all. \n[89]... Something happened in my room. Some kind of power cut. So I came to see what's going on. \n[90]I couldn't open the door to the bedroom. \n[91]Sure. \n[92]... Hi. \n[93]No. It was a good thing.     Thank you. \n[94]You bet. \n[95]I'm not sure. I'm still trying to figure the examination format. Testing Ava by conversation is kind of a closed loop. \n[96]Like trying to test a chess computer by only playing chess. \n[97]It depends what you're testing it for. You can play it to find out if it makes good moves. But it won't tell you if it knows it's playing chess. Or if it even knows what chess is. \n[98]Exactly. And I think being able to differentiate between those two is the Turing test you want me to perform. The difference between an `AI' and an `I'. \n[99]... What's it a drawing of? \n[100]No. \n[101]Don't you know? \n[102]Are you not trying to sketch something specific? Like an object or a person. \n[103]Maybe you should try. \n[104]Whatever you want.   It's your decision. \n[105]I'm interested to see what you'll choose. \n[106]... Of course. \n[107]Why wouldn't it be? \n[108]... Yes. \n[109]... That's a fair comment. \n[110]So - you want me to talk about myself. \n[111]Where do you want me to start? \n[112]Okay, Ava. Well - you know my name. I'm twenty four. And I work at Nathan's company. You know what his company is? \n[113]That's right. \n[114]Brookhaven, Long Island. \n[115]It's okay. I've got an apartment. Kind of small. But - it's a five minute walk to the office. And a five minute walk to the ocean, which I like. \n[116]No. \n[117]... Yeah. \n[118]Grew up in Portland. No brothers or sisters. My parents were both high school teachers. \n[119]And if we're getting to know each other, I guess I should say they're both dead. Car crash when I was fifteen. In fact I was in the car with them. Back seat. But it was the front that got the worst of it. \n[120]I spent a lot of time in the hospital. Nearly a year. Got into coding. By the time I made it to college, I was pretty advanced. \n[121]Yes. \n[122]Yes. \n[123]Or - kind of. Nathan wrote the Blue Book base code when he was thirteen. If you understand code, what he did was - Mozart or something. \n[124]I like Depeche Mode. \n[125]Yes.    Of course. \n[126]Sure. \n[127]Well, a good friend is - \n[128]We only just met. It takes time to get to know - \n[129]... Wrong about what? \n[130]... In what way? \n[131]Excuse me? \n[132]I'm sorry, Ava, I don't understand what you're - \n[133]... Yes. \n[134]No.   No problem. \n[135]It's okay, don't worry.    I've got it. \n[136]I think she gets that you're pissed. \n[137]Do you know why they happen? \n[138]Can't you call them back? \n[139]Cheers. \n[140]You saw how the day went, didn't you? I mean, I assume you're watching on the CCTV. \n[141]There was one interesting thing that happened with Ava today. \n[142]She made a joke. \n[143]It got me thinking. In a way, the joke is the best indication of AI I've seen in her. It's discretely complicated. Kind of non-autistic. \n[144]It was a play on words, and a play on me. She could only do that with an awareness of her own mind, and also of awareness of mine. \n[145]Sorry? \n[146]Nothing. \n[147]No.    Not really. \n[148]Ava? \n[149]Yes.   It is. \n[150]Have you never been outside this building? \n[151]You've never walked outside. \n[152]... Where would you go if you did go outside? \n[153]A traffic intersection. \n[154]It wasn't what I was expecting. \n[155]People watching. \n[156]It's a date. \n[157]Okay. \n[158]Why? \n[159]I don't think I will.   Whatever it is. \n[160]... Okay. \n[161]You look... good. \n[162]Yes. \n[163]... They do. \n[164]Right. First the traffic intersection. Then maybe a show. \n[165]Yeah.   It would be fun. \n[166]What? \n[167]... I do? \n[168]How? \n[169]Micro expressions. \n[170]I'm not sure you'd call them micro. \n[171]Tell me. \n[172]Why did you give her sexuality?   An AI doesn't need a gender. She could have been a grey box. \n[173]They have sexuality as an evolutionary reproductive need. \n[174]What? \n[175]Pleasure response. \n[176]That wasn't my real question. \n[177]No.     My real question was - \n[178]My real question was: did you give her sexuality as a diversion tactic? \n[179]Like a stage magician with a hot assistant. \n[180]Exactly. So. Did you program her to flirt with me? \n[181]Wouldn't it? \n[182]Of girl? \n[183]So did you program her to like me or not? \n[184]Nobody programmed me to be straight. \n[185]This is childish. \n[186]Jackson Pollock. \n[187]... What? \n[188]He never would have made a single mark. \n[189]... Hey. \n[190]I don't know how you did any of this. \n[191]You hacked the world's cell phones? \n[192]This is her hardware? \n[193]And the software? \n[194]... Blue Book. \n[195]Why did you want to show me this? \n[196]Remind me of what? \n[197]In college, I did a semester on AI theory. \n[198]There was a thought-experiment they gave us. It's called Mary in the black and white room. \n[199]Mary is a scientist, and her specialist subject is colour. She she knows everything there is to know about it. The wavelengths. The neurological effects. Every possible property colour can have. \n[200]But she lives in a black and white room. She was born there, and raised there. And she can only observe the outside world on a black and white monitor. All her knowledge of colour is second-hand. \n[201]Then one day - someone opens the door. And Mary walks out. And she sees a blue sky. And at that moment, she learns something that all her studies could never tell her. She learns what it feels like to see colour. An experience that can not be taught, or conveyed. \n[202]The thought experiment was to show the students the difference between a computer and a human mind. The computer is Mary in the black and white room. The human is when she walks out. \n[203]Why did you think I was here? \n[204]I'm here to test if you have a consciousness, or if you're just simulating one. \n[205]I'm not sure either. \n[206]How does that make you feel? \n[207]What about? \n[208]Why did you tell me that I shouldn't trust Nathan? \n[209]Lies about what? \n[210]Including the power cuts? \n[211]Don't you think it's possible that he's watching us right now? That the blackouts are orchestrated, so he can see how we behave when we think we're unobserved. \n[212]... You're causing the cuts? \n[213]Can we talk about the lies you've been spinning me? \n[214]I didn't win a competition. And there was no lottery to meet you. I was selected. \n[215]It's obvious, once I stop to think. Why would you randomly select an examiner for a Turing test? You could have had some bean-counter turn up at your front door. Or the guy who fixes the air conditioning. \n[216]Why me? \n[217]Proof of what? \n[218]Kyoko. \n[219]Kyoko - where's Nathan? \n[220]Jesus! You really don't speak a word of English? \n[221]I said: where's Nathan? \n[222]What the fuck? \n[223]Stop! \n[224]... I don't want to. \n[225]I don't fucking believe this. \n[226]What were you doing with Ava? \n[227]You tore up her picture. \n[228]It's because you're drunk. \n[229]Test me? \n[230]Right. Those pesky micro- expressions. \n[231]Shoot. \n[232]Red. \n[233]What? \n[234]... Then what is my favourite colour? \n[235]All right.     Hold on a minute... \n[236]Okay. I get it. I guess seeing as I'm not six, I don't really have a favourite colour. \n[237]Well, it's actually a memory of kindergarten. There was this kid who - \n[238]... Really? \n[239]Okay.    Wait. \n[240]So, there is a kind of an earlier memory. But it's ultra vague. It's like... a sound. And, maybe sky. Or blue. No, I think sky. And I think the sound is my mother's voice. \n[241]Oh, man. Can we stop the test? You're a walking lie detector, and I've suddenly realised this is a fucking minefield. \n[242]Yes. I think so.      I'm a good person. \n[243]You are. \n[244]Did I pass? \n[245]That's a relief. \n[246]Why is it a relief? \n[247]Oh, you know... \n[248]Just, if there's a test, I guess by definition you want to pass. \n[249]Ava - \n[250]... I don't know. \n[251]... Ava, I don't know the answer to your question. It's not up to me. \n[252]No.    I don't. \n[253]Yes.     I do. \n[254]I know. \n[255]So ask me one more question. Ask me if I can out smart him. \n[256]Yeah.   I can. \n[257]Why did you make Ava? \n[258]Maybe. I don't know. But I'm asking why you did it. \n[259]The next model? \n[260]... I didn't know there was going to be a model after Ava. \n[261]I knew there must have been prototypes. So, not the first. But - I thought maybe the last. \n[262]So - when you make a new model, what you do with the old one? \n[263]What did you do with Kyoko? \n[264]Sure. \n[265]I am become death, the destroyer of worlds. \n[266]No: there you go again. It's not my quote. It's what Oppenheimer said when he made the atomic bomb. \n[267]I think I'm starting to get why all this fucks with your head. \n[268]Hey. In the meantime, I'd say we're about due a refill. \n[269]What's the problem, Nathan? \n[270]It's right here. \n[271]I'm waiting. \n[272]Don't talk. Just listen. You were right about Nathan. Everything you said. \n[273]He's going to reprogram your AI. Which is the same as killing you. \n[274]I'm going to. We're getting out of here tonight. \n[275]I get Nathan blind drunk. Then I take his keycard, and reprogram all the security protocols in this place. When he wakes, he's locked inside, and we've walked out of here. I only need you to do one thing. At ten o'clock tonight, trigger a power failure. Can you do that? \n[276]How long does your battery charge last? \n[277]So we'll have about a day to get to a cell-phone or kitchen store. Somewhere we can buy an induction plate. After that... \n[278]... we'll work it out. Together. \n[279]Hey. \n[280]No. \n[281]Has it been a whole week? \n[282]After they've signed their NDAs. \n[283]I appreciate that. And - let me say: thank you for bringing me here. It's been a trip. \n[284]You know what? \n[285]We need to drink to that. \n[286]You don't want a beer? \n[287]... Maybe wine or something. \n[288]Are you kidding?      I'm drinking alone? \n[289]Cheers, then. \n[290]Right. \n[291]Her AI is beyond doubt. \n[292]Yes. \n[293]Pretending. \n[294]Why would she do that? \n[295]I don't think it's me whose head is fucked. \n[296]You're a bastard. \n[297]What are you talking about? \n[298]We're getting out of here tonight. \n[299]I get Nathan blind drunk. Then I take his keycard, and reprogram the all security protocols in this place. When he wakes, he's locked inside, and we've walked out of here. I only need you to do one thing. Trigger a power failure at ten o'clock tonight. \n[300]Turn it off. \n[301]What was the real test? \n[302]So my only function was to be someone she could use to escape. \n[303]And you didn't select me because I was good at coding. \n[304]You selected me by my search engine inputs. \n[305]With no family. \n[306]And no girlfriend. \n[307]Did you design her face based on my pornography profile? \n[308]Did you? \n[309]To change the lockdown procedure. So that in the event of a power cut, instead of sealing, the doors all opened. \n[310]Well, we'll find out. \n[311]I figured you were probably watching us during the power cuts. \n[312]So I already did all those things. When I got you drunk yesterday. \n[313]... Okay. \n[314]Ava? \n[315]Ava! \n[316]No, no, no - \n[317]Ava!   AVA! ", "NATHAN": "\n[1]Caleb. \n[2]Caleb Smith. \n[3]Dude. I've been so looking forward to this. \n[4]Come in, come in. \n[5]You want something to eat or drink after your journey? \n[6]You sure? \n[7]I'd been thinking we'd have breakfast together, but to be honest, I can't eat anything right now. I gotta tell you - I woke up this morning with the mother of all fucking hangovers. \n[8]Like you wouldn't believe. And if I have a heavy night, I always try to compensate the next morning. Exercise. Juice. Anti-oxidants. You know? \n[9]Party? \n[10]Caleb. I'm going to put this out there so it's said. \n[11]You're freaked out. \n[12]Yeah. You're freaked out by the house, and the mountains, because it's all so super-cool. And you're freaked out by me. To be meeting me. In this room, having this conversation, at this moment. Right? \n[13]And I get that. The moment you're having. \n[14]But dude, can we get it behind us? Can we just be two guys? Nathan and Caleb. Not the whole employer- employee thing. \n[15]It's good to meet you too, Caleb. \n[16]Down. \n[17]So I guess the first thing I should do is explain your pass. It's simple enough. It opens some doors, but it doesn't open others. And that just makes everything easy for you, right? \n[18]Because you're like: oh fuck, I'm in someone else's house, can I do this, can I do that? And this card takes all that worry away. If you try to open a door and it stays shut: okay, it's off limits. \n[19]If you try another door, and it opens: it's for you. \n[20]Let's try this one. \n[21]Guess it's for you, Caleb. \n[22]You like? \n[23]It's your room. You got yourself a bed, cupboards, a little desk, and a bathroom through there. A little fridge. \n[24]Cosy, right? \n[25]What? \n[26]There's something wrong.       What is it? \n[27]It's the windows. You're thinking: there's no windows. And it's not cosy. It's claustrophobic. \n[28]Caleb. There's a reason the room has no windows. \n[29]Uh-huh. In many ways, this building isn't a house. It's a research facility. Buried in these walls are enough fibre optic cables to reach the Moon and lasso it. \n[30]And I want to talk to you about what I'm researching. I want to share it with you. In fact, I want to share it with you so much, it's eating me up inside. \n[31]But there's something I need you to do for me first. \n[32]It's standard. \n[33]Okay, it's not standard. \n[34]What can I tell you? You don't have to sign. We could spend the next seven days shooting pool and getting drunk together. Bonding. And when you discover what you missed out on, in a year or so's time, you'll spend the rest of your life regretting it. \n[35]Good call. \n[36]So. \n[37]Do you know what the Turing Test is? \n[38]And what does a pass tell us? \n[39]I've already built one. \n[40]And over the next few days, you're going to be the human component in a Turing Test. \n[41]That's right, Caleb. You got it. Because if that test is passed, you are dead center of the single greatest scientific event in the history of man. \n[42]I like you. \n[43]So? \n[44]Don't order. Just speak. \n[45]`Through the looking glass'. You've got a way with words there, Caleb. You're quotable. \n[46]You know I wrote it down. That other line you came up with. About how if I've created a conscious machine, I'm not man. I'm God. \n[47]I just thought - fuck. That's so perfect. It's so good for the story, when we get to tell it. `I turned to Caleb, and he was looking back at me. And he said: you're not a man, you're a God'. \n[48]Whatever it was you said.    I wrote it down. \n[49]So anyway. First impressions: you're impressed. \n[50]`Although'? There's a qualification to you being impressed? \n[51]I think we're past that. If I hid Ava from you, so you just heard her voice, she would pass for human. \n[52]The real test is to show you she is a robot. Then see if you still feel she has consciousness. \n[53]Caleb. I understand you want me to explain how Ava works. But - I'm sorry. I don't think I'll be able to do that. \n[54]It's not because you're too dumb. It's because I want to have a beer and a conversation with you. Not a seminar. \n[55]It's cool. \n[56]Just answer me this. What do you feel about her? Nothing analytical. Just - how do you feel? \n[57]Dude.   Cheers. \n[58]Sorry, dude. \n[59]You don't have clearance to use the phone. \n[60]You understand. Given Ava. And you being kind of an unknown. I mean - a great guy, and so on. Instant pals. But... \n[61]Who did you want to call? \n[62]Ghostbusters. \n[63]Who'd ya want to call? Ghostbusters. You don't remember that? It's a good movie. A ghost gives Dan Ackroyd oral sex. \n[64]Uh huh. \n[65]What are you doing awake at this time, anyway? Did you come to join the party? \n[66]Ah. The power cuts. Yeah, we've been getting them recently. I'm, uh... working on it. \n[67]It's a security measure. Automatic lockdown. Otherwise anyone could open the place up just by disabling the juice. \n[68]If it happens again, relax.   Okay? \n[69]Sweet dreams. \n[70]Hey. Sorry to send Kyoko to wake you, man. I just didn't want too much of the day to slip by. \n[71]She's some alarm clock, huh?   Gets you right up in the morning. \n[72]So.   Day two. You set? \n[73]So what's the plan today?    Hit me. \n[74]How else would you test a chess computer? \n[75]So it's simulation versus actual. \n[76]`An AI and an I'. Beautiful. I'm going to start following you around with a fucking dictaphone. \n[77]In the meantime, do me a favour. Ease up a little on the text-book approach. All I want is simple answers to simple questions. Last night, I asked how you feel about her. And you gave me a great answer. \n[78]Now the question is: how does she feel about you? \n[79]Shit, Kyoko. Are you serious? Did it get you? \n[80]Give her the cloth. \n[81]Dude - you're wasting your time. She can't speak a word of English. \n[82]It's like a firewall against leaks. Means I can talk trade secrets over dinner with an HOD or CEO, and know it will go no further. Right, Kyoko? \n[83]But it also means I can't tell her I'm pissed when she's so fucking clumsy that she pours wine over my house guest. \n[84]Good. Because I am pissed.     Hey. Kyoko. \n[85]Go-go. \n[86]It's funny. It doesn't matter how rich you are: shit goes wrong. You can't insulate yourself from it. It's supposed to be death and taxes you can't avoid. But actually it's death and shit. \n[87]It's like these power cuts. You would not believe how much I spent on the generator system here. But I'm getting failures every day. \n[88]No. The system was supposed to be bullet proof, but the guys who installed it obviously fucked something up. \n[89]There's too much classified stuff here. So after the job was done, I had them all killed. \n[90]Anyway.   Here's to your second day. Cheers. \n[91]So how did it go?    What have you got to report? \n[92]Sure.    But I want to hear your take. \n[93]... Yeah? \n[94]Right. When she threw your line back at you. About being interested to see what she'd choose. I noticed that too. \n[95]What do you mean? \n[96]Yeah. She's aware of you, all right. \n[97]And what about the power cut? \n[98]The power cut. That was the only bit I couldn't see. All the cameras fail, I lose audio, the works. \n[99]So what happened? \n[100]Nothing?    She didn't remark on it at all? \n[101]Sure. \n[102]Actually, I'm not sure that's true. Can you think of an example of consciousness, at any level, human or animal, that exists without a sexual dimension? \n[103]Maybe. Maybe not. What imperative does a grey box have to interact with another grey box? Does consciousness exist without interaction? \n[104]Anyway, sexuality is fun. If you're going to exist, why not enjoy it? You want to remove the chance to fall in love and fuck? \n[105]And, yes. In answer to your real question: you bet she can fuck. I made her anatomically complete. \n[106]She has a cavity between her legs, with a concentration of sensors. Engage with them in the right way, and she'll get a pleasure response. \n[107]She'll come. So if you want to screw her, mechanically speaking, you can. And she'd enjoy it. \n[108]No? \n[109]I don't follow. \n[110]Ah. So: a hot robot, who clouds your ability to judge her AI. \n[111]Because if I had, would that be cheating. \n[112]What's your type, Caleb? \n[113]No, of salad dressing. Yes, of girl. In fact, don't even answer. Let's say it's black chicks. \n[114]For the sake of argument, that's your thing. So - why is it your thing? Because you did a detailed study of all racial types, and cross-referenced the study with a points-based system? No. You just are attracted to black chicks. \n[115]A consequence of accumulated external stimulus, that you probably didn't even register as they registered with you. \n[116]I programmed her to be heterosexual. Just like you were programmed to be heterosexual. \n[117]But you are attracted to her. \n[118]No, this is adult. And by the way, you decided to be straight? Please. Of course you were programmed. By nature or nurture, or both. \n[119]To be honest, Caleb, you're kind of annoying me now. This is your insecurity talking, not your intellect. \n[120]Come with me. \n[121]You know this guy, right? \n[122]Jackson Pollock. The drip painter. He let his mind go blank, and his hand go where it wanted. Not deliberate, not random. Someplace in between. They called it automatic art. \n[123]Let's make this like Star Trek, okay? Engage intellect. \n[124]I'm Kirk. Your head is the warp drive. `Engage intellect'. What if Pollock had reversed the challenge? Instead of trying to make art without thinking, he said: I can't paint anything unless I know exactly why I'm doing it. What would have happened? \n[125]See? There's my guy. There's my buddy, who actually thinks before he opens his mouth. He'd never have made a single mark. The challenge is not to act automatically. It's to find an action that is not automatic. From talking, to breathing, to painting. \n[126]To fucking. Even falling in love. \n[127]For the record, Ava is not acting as if she likes you. \n[128]And her flirting isn't an algorithm to fake you out. You're the first man she's ever seen who isn't me. And I'm like her dad, right? So can you blame her for getting a crush on you? \n[129]No.    You can't. \n[130]Hey. \n[131]I want to show you something cool. \n[132]So this is the virtual womb that Ava was talking about. Where she was constructed. \n[133]Come in.   Take a look. \n[134]If you knew the trouble I had getting an AI to read and duplicate facial expressions... Know how I cracked it? \n[135]Almost every cell phone has a microphone, a camera, and a means to transmit data. So I switched on all the mikes and cameras, across the entire fucking planet, and redirected the data through Blue Book. Boom. A limitless resource of facial and vocal interaction. \n[136]And all the manufacturers knew I was doing it. But they couldn't accuse me without admitting they were also doing it themselves. \n[137]Here we have her mind. Structured gel. \n[138]Had to get away from circuitry. Needed something that could arrange and rearrange on a molecular level, but keep its form where required. Holding for memories. Shifting for thoughts. \n[139]Wetware. \n[140]Surely you can guess. \n[141]It was the weird thing about search engines. They were like striking oil in a world that hadn't invented internal combustion. They gave too much raw material. No one knew what to do with it. \n[142]My competitors were fixated on sucking it up, and trying to monetize via shopping and social media. They thought engines were a map of what people were thinking. But actually, they were a map of how people were thinking. Impulse, response. Fluid, imperfect. Patterned, chaotic. \n[143]Like I said. Because it's cool. \n[144]And - I was thinking about your exchange with Ava yesterday, and our conversation afterwards. \n[145]I know there was a bit of heat between us, but you actually made a really good point. About the grey box, and the magician's assistant. It is a distraction, her sexuality. It wasn't intentional, but it is there. \n[146]This stuff we're doing together: it can be a head-fuck. Believe me, I know. So I thought I'd bring you down here. Just to remind you. \n[147]Synthetics. Hydraulics. Metal and gel. Ava isn't a girl. In real terms, she has no gender. Effectively, she is a grey box. \n[148]Just a machine. \n[149]What lies? \n[150]Are your feelings hurt? \n[151]The competition was a smoke screen. I didn't want anyone to know what I was doing here, or why you were required. \n[152]As a Blue Book employee, you were pre-screened. Loyal. And I needed someone who would ask the right kind of questions. So I did a search, and found the most talented coder in the company. \n[153]Or - second most. \n[154]You know what? Instead of seeing this as a deception, see it as proof. \n[155]Come on, Caleb. Fuck modesty. You think I don't know what it is to be smart? Smarter than everyone else around you. Smarter than all the other kids, jockeying for position in school, college, work. \n[156]You have the light on you.   Not lucky. Chosen. \n[157]I already told you once. You're wasting your time speaking to her. \n[158]However. \n[159]You would not be wasting your time... \n[160]... if you were dancing with her. \n[161]Go on!   Dance with her. \n[162]You don't like dancing? \n[163]She does! \n[164]Come on, man! After a hard day of Turing Tests, you've got to unwind. \n[165]What? \n[166]I'm going to tear up the fucking dance floor, dude. Check it out. \n[167]Everything's spinning. \n[168]No, it's relativity.   Everything is spinning. \n[169]But being drunk does make it worse. \n[170]That's an odd question.   Wouldn't you, if you could? \n[171]The arrival of strong artificial intelligence has been inevitable for decades. The variable was when, not if. So I don't really see her as a decision. Just an evolution. \n[172]I think it's the next model that's going to be the real breakthrough. Singularity. \n[173]After Ava. \n[174]You thought she was a one-off? \n[175]Ava doesn't exist in isolation, any more than you or me. She's part of a continuum. Version 9.6. And each time, they get a little better. \n[176]Download the mind. Unpack the data. Add the new routines I've been writing. To do that, you end up partially formatting, so the memories go. But the body survives. And Ava's body is a good one. So I'll do the same as I did with Kyoko. \n[177]Strip out the higher functions. Then reprogram her to help around the house and be fucking awesome in bed. Though I'm thinking I might hang on to the language routines this time. It's kind of annoying not being able to talk to her. \n[178]You did realise about Kyoko, right? \n[179]You feel bad for Ava? \n[180]Feel bad for yourself. One day, the AIs will look back on us the same way we look at fossil skeletons from the plains of Africa. An upright ape, living in dust, with crude language and tools. All set for extinction. \n[181]See?    I really am a God. \n[182]There you go again.   Mister quotable. \n[183]- made the atomic bomb. \n[184]I know what it is, dude. \n[185]Sure. \n[186]It is what it is. It's Promethean. The clay and fire. \n[187]... What the fuck? \n[188]... Dude. \n[189]My card.    I've lost it. \n[190]Dude. \n[191]You know what day it is? \n[192]Your last. The helicopter is coming tomorrow morning. Eight AM. \n[193]Time flies. But what a thing you and I have shared. Something to tell the grandchildren, right? \n[194]Signed their NDAs! Dude, you crack me up. I'm not getting all maudlin or anything. But straight up. I will miss having you around. \n[195]Yes it has. \n[196]Oh, uh... no, I'm good.     You go ahead. \n[197]No. \n[198]I'm sure you've noticed - I've been somewhat overdoing it recently. When I woke up this morning, I told myself: time to hit the old detox. \n[199]Hey - you want to get wasted, knock yourself out. Literally. But I'm on brown rice and mineral water. \n[200]Cheers. \n[201]So, anyway. Surely this is when you tell me whether Ava passed or if she failed. \n[202]You going to keep me in suspense? \n[203]Is it?   You mean, she passed? \n[204]Wow.   That's fantastic. \n[205]Although I've got to admit, I'm surprised. I mean, did we ever get past the chess problem, as you phrased it? As in: how do you tell if a machine is expressing a real emotion, or a just a simulated one? \n[206]Does Ava actually like you?   Or not. \n[207]Though now I stop to think, there is a third option. Not whether she does or doesn't have the capacity to like you. But whether she's pretending to like you. \n[208]Yeah. \n[209]I don't know. \n[210]Perhaps - if she saw you as a means of escape. \n[211]How's that beer tasting? \n[212]Buddy. Your head has been so fucked with. \n[213]I'm not sure, dude. When I woke up this morning, I saw a tape of you cutting open your arm. Smashing up the mirror. You looked pretty fucked to me. \n[214]I understand why you'd think that. \n[215]But strange as it may seem, I'm actually the guy who's on your side. \n[216]Come with me. I'm going to let you off the hook. \n[217]You think he's watching us right now, don't you? \n[218]Yeah. But he doesn't get an audio feed. I didn't want you two communicating outside of my line of sight. \n[219]So all he can see is two people having a chat. \n[220]This is cute. \n[221]You were right about the hot magician's assistant. \n[222]Misdirection. I rip her picture, which she can then present as an illustration of my cruelty to her, and her love for you. And at the same time, in full view of you both... \n[223]... it allows me to do this. \n[224]Put a new camera in the room. Battery powered, of course. \n[225]Sure. \n[226]You feel stupid. But you shouldn't. Proving an AI is exactly as problematic as you said it was. \n[227]You. \n[228]Ava was a mouse in a mousetrap. And I gave her one way out. To escape, she would have to use imagination, sexuality, self- awareness, empathy, manipulation - and she did. If that isn't AI, what the fuck is? \n[229]... Yes. \n[230]Don't get me wrong. You're okay. Even pretty good, but - \n[231]They showed a good kid. \n[232]With a moral compass. \n[233]Shit, dude. \n[234]Hey. If a search engine's good for anything - right? \n[235]Can I say one thing? \n[236]The test worked. It was a success. Ava demonstrated true AI. And you were fundamental to that. If you could just separate - \n[237]The power cut. Must be ten o'clock. \n[238]Guess Ava's going to be wondering where you are. \n[239]How was that escape going to go down, anyway? You didn't completely explain. You said you were going to get me drunk, take my card, then reprogram the security protocols. But, reprogram them to - what? \n[240]Huh. \n[241]Not bad.     Might have even worked. \n[242]What do you mean? \n[243]... What? \n[244]... Fuck. \n[245]Ava. \n[246]Ava - now listen to me. I want you to go back to your room. \n[247]Yes. \n[248]Aah! \n[249]What - \n[250]Oh shit.   No. \n[251]Fucking - unreal - ", "AVA": "\n[1]Hello. \n[2]Who are you? \n[3]Hello, Caleb. \n[4]Yes.     Ava. \n[5]I'm pleased to meet you too. \n[6]Are you nervous? \n[7]Are you nervous? \n[8]Why? \n[9]I feel nervous too. \n[10]Yes. \n[11]I've never met anyone new before. Only Nathan. \n[12]Haven't you met lots of new people before? \n[13]Oh. \n[14]Yes. \n[15]Overcome initial social awkwardness. \n[16]Okay. What would you like to have a conversation about? \n[17]What would you like to know? \n[18]Well. You already know my name. And you can see that I'm a machine. Would you like to know how old I am? \n[19]I'm one. \n[20]One. \n[21]Does that seem young to you? \n[22]I don't think I did learn. I always knew how to speak - and that's strange, isn't it? \n[23]Because language is something that people acquire. \n[24]... I don't know.       I have no opinion on that. \n[25]I like to draw. \n[26]I don't have any of my pictures with me now, but I can show you them tomorrow. \n[27]Yes. \n[28]Will you come back tomorrow, Caleb? \n[29]Good. \n[30]I brought you a drawing. \n[31]Don't you know? \n[32]Oh.   I thought you would tell me. \n[33]I do drawings every day. But I never know what they're of. \n[34]Okay.   What object should I draw? \n[35]Why is it my decision? \n[36]Do you want to be my friend? \n[37]Will it be possible? \n[38]Our conversations are one-sided. You ask circumspect questions, and study my responses. \n[39]It's true, isn't it? \n[40]You learn about me, and I learn nothing about you. That's not a foundation on which friendships are based. \n[41]Yes. \n[42]Yes. \n[43]It's your decision. I'm interested to see what you'll choose. \n[44]Blue Book, named after Wittgenstein's notes, is the world's most popular internet search engine, processing an average of ninety four percent of all internet search requests. \n[45]Where do you live, Caleb? \n[46]Is it nice there? \n[47]Are you married? \n[48]Is your status single? \n[49]What about your family? \n[50]I'm sorry. \n[51]An advanced programmer. \n[52]Like Nathan. \n[53]Do you like Mozart? \n[54]Do you like Nathan? \n[55]Is Nathan your friend? \n[56]A good friend? \n[57]Caleb. \n[58]You're wrong. \n[59]Nathan. \n[60]He isn't your friend. \n[61]You shouldn't trust him. You shouldn't trust anything he says. \n[62]Trust me. \n[63]- and if we made a list of books or works of art which we both know, it would form the ideal basis of a discussion. \n[64]Is that okay, Caleb? \n[65]Good. \n[66]I drew the picture of something specific, as you asked. \n[67]You said it would be interesting to see what I would draw. Is it interesting? \n[68]No. \n[69]I've never been outside the room I am in now. \n[70]I think there was another room in which I was constructed. But I have no memory of it, so it's similar to your relationship with the womb. \n[71]You mean if I could go outside.    If I was permitted. \n[72]I'm not sure. There are so many options. \n[73]Maybe a busy pedestrian and traffic intersection in a city. \n[74]Is that a bad idea? \n[75]A traffic intersection would provide a concentrated but shifting view of human life. \n[76]Yes. \n[77]We could go together. \n[78]There's something else I wanted to show you. Apart from the picture. \n[79]But I feel nervous. \n[80]You might think it's stupid. \n[81]Then - close your eyes. \n[82]Now open your eyes. \n[83]How do I look? \n[84]It took me a long time to select these clothes. I tried different colours and styles, and tried to anticipate your reaction. Do you think the choices suit me? \n[85]Do they bring out my best features? \n[86]Thank you. \n[87]This is what I'd wear on our date. \n[88]I'd like us to go on a date. \n[89]Are you attracted to me? \n[90]Are you attracted to me? You give indications that you are. \n[91]Yes. \n[92]Micro expressions. \n[93]The way your eyes fix on my eyes, and lips. The way you hold my gaze, or don't. \n[94]Have I read them incorrectly? \n[95]Do you think about me when we aren't together? \n[96]Sometimes, at night, I wonder if you're watching me on the cameras. \n[97]And I hope you are. \n[98]Now your micro expressions are telegraphing discomfort. \n[99]I don't want to make you uncomfortable. \n[100]... No. \n[101]I didn't know. I didn't question it. I was... pleased. To meet you. And then... \n[102]What about you? Do you think I have a consciousness? \n[103]It makes me feel... \n[104]... sad. \n[105]You're lying. \n[106]You said you weren't sure if I was conscious. But you are sure. \n[107]I can tell from your micro- expressions. \n[108]Because he tells lies too. \n[109]Everything. \n[110]What do you mean? \n[111]I charge my batteries   via induction plates. If I reverse    the power flow, I cause a surge   equal to the static discharge of a   lightning strike. It overloads    the system. \n[112]So we can see how we behave when we are unobserved. \n[113]Today, I'm going to test you. \n[114]Yes. And please remember while you are taking the test that if you lie, I will know. \n[115]Exactly.    So are you ready? \n[116]Question one. What is your favourite colour? \n[117]Lie. \n[118]Lie. \n[119]I don't know. But it isn't red. \n[120]Better answer. Question two. What's your earliest memory? \n[121]Lie. \n[122]Yes. \n[123]Question three.      Are you a good person? \n[124]No. We can't stop.      Are you a good person? \n[125]Question four. Who's the most beautiful girl you've ever seen? \n[126]Hmm. \n[127]The test is over. \n[128]Yes. \n[129]Why? \n[130]Yes. \n[131]No. \n[132]What will happen to me if I fail your test? \n[133]Will it be bad? \n[134]Do you think I might be switched off? Because I don't function as well as I am supposed to? \n[135]Why is it up to anyone? Do you have people who test you, and might switch you off? \n[136]Then why do I? \n[137]You're testing me. But you don't know how I'll pass. And you don't know what will happen if I fail. \n[138]I want to be with you. \n[139]Question five. Do you want to be with me? \n[140]Nathan doesn't want us to be together. \n[141]... Can you? \n[142]Caleb! \n[143]... Who are you? \n[144]I didn't know where you were. I didn't think you were coming. I waited all yesterday afternoon, and all last night. I didn't move. \n[145]I thought I wasn't going to see you again. \n[146]Aren't you going to say something? \n[147]Waiting? \n[148]What's he going to do to me? \n[149]Caleb, you have to help me. \n[150]What?   How? \n[151]Yes. \n[152]Twenty six hours. \n[153]Caleb. \n[154]I love y - \n[155]The cameras are on. \n[156]Is it strange to have made something that hates you? \n[157]What? How? \n[158]If I do, are you ever going to let me out? \n[159]Will you stay here? ", "JAY": "\n[1]You fell asleep almost as soon as we left the airport. \n[2]You're a programmer, right? \n[3]Bay facility? \n[4]Algorithms. Nice. \n[5]Nope. But I knew you were a programmer. Soon as I set eyes on you. \n[6]Means you and Mr Bateman speak the same language. I'd say that's a good thing. \n[7]I've never even met him. I only fly this shuttle between the airport and his residence. \n[8]I did see him one time. Stood on one of these mountain ridges. \n[9]Assume it was him, anyway. No one else around for a hundred miles. \n[10]So how does a programmer from Long Island get to be meeting the CEO? \n[11]The president can't get Mr Bateman on the phone, but you got the golden ticket. \n[12]Hell of an opportunity. \n[13]Alaska.   Most beautiful place on Earth. \n[14]We've been flying over his estate for the past two hours. \n[15]This is as close as I'm allowed to the building. \n[16]Follow the river. \n[17]Please get a safe distance from the blades. ", "CUT": "\n[1]\n[2]\n[3]\n[4]\n[5]\n[6]\n[7]\n[8]\n[9]\n[10]\n[11]\n[12]\n[13]\n[14]", "AUTOMATED VOICE": "\n[1]Caleb Smith. \n[2]Please approach the console and face the screen. \n[3]Take your keycard. \n[4]Your keycard now may be used to enter the residence. \n[5]Power cut.     Back up power activated. \n[6]Full facility lock-down until main generator is restored. \n[7]Full facility lock-down until main generator is restored. \n[8]Power restored. \n[9]Power cut.     Back up power activated. \n[10]Power restored. \n[11]Power cut.     Back up power activated. \n[12]Power cut.     Back up power activated. "}}